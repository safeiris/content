✅ Server running: UI + API on http://127.0.0.1:8000
 * Serving Flask app 'server'
 * Debug mode: off
{"timestamp": "2025-10-24T13:16:47.722556Z", "level": "INFO", "logger": "werkzeug", "message": "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n * Running on http://127.0.0.1:8000", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:16:47.722713Z", "level": "INFO", "logger": "werkzeug", "message": "\u001b[33mPress CTRL+C to quit\u001b[0m", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:17:35.998933Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:17:35] \"\u001b[32mGET / HTTP/1.1\u001b[0m\" 302 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:17:36.011110Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:17:36] \"GET /login?next=/ HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:17:36.294219Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:17:36] \"\u001b[32mGET /favicon.ico HTTP/1.1\u001b[0m\" 302 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:17:36.324066Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:17:36] \"GET /login?next=/favicon.ico HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:17:39.172654Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:17:39] \"\u001b[32mPOST /login?next=/ HTTP/1.1\u001b[0m\" 302 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:17:39.181466Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:17:39] \"GET / HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:17:39.206289Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:17:39] \"\u001b[36mGET /styles.css HTTP/1.1\u001b[0m\" 304 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:17:39.210834Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:17:39] \"\u001b[36mGET /script.js HTTP/1.1\u001b[0m\" 304 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:17:39.238942Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:17:39] \"GET /api/pipes HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:17:39.303540Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:17:39] \"GET /api/artifacts HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:17:39.361015Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:17:39] \"GET /favicon.ico HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:17:41.338610Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "trace_id": "56fd6da0f88d4e179365cd66f41f9cba", "name": "httpx"}
{"timestamp": "2025-10-24T13:17:41.344656Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:17:41] \"GET /api/health?theme=finance HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:18:12.214600Z", "level": "INFO", "logger": "content_factory.jobs.runner", "message": "job_enqueued", "trace_id": "e82643c45152484db17b13fd7e3d1cd3", "name": "content_factory.jobs.runner", "job_id": "1bcb55179c6e41b2ad9933ae25fb339b"}
{"timestamp": "2025-10-24T13:18:12.215290Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:18:12] \"\u001b[35m\u001b[1mPOST /api/generate HTTP/1.1\u001b[0m\" 202 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:18:12.218161Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "SKELETON_ESTIMATE predicted=1484 start_max=1780 cap=3600 → resolved max_output_tokens=1780", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:18:12.218394Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=3781 attempt=1 max_tokens=1780", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:18:12.618223Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:18:12.619483Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1780 (requested=1780, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:12.619609Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESPONSES_PARAM_OMITTED omitted=['temperature'] model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:12.621536Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:12.621720Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:12.621902Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3857", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:12.621966Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:12.622025Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:12.821954Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:18:12] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:18:13.608498Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:18:13] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:18:14.627397Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:18:14] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:18:15.950680Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:18:15] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:18:18.013355Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:18:18] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:18:21.009759Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:18:21] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:18:24.008398Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:18:24] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:18:28.009255Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:18:28] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:18:31.921278Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:18:31.923270Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:31.923366Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:31.923481Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:31.923560Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:31.923641Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1780 to=2670 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:31.923747Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0f72619ed07fbf250068fb7c94d4e08199a46a356657415f44", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:31.923851Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:31.923942Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:31.924004Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3857", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:31.924059Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:31.924115Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:33.007207Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:18:33] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:18:38.009767Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:18:38] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:18:43.008893Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:18:43] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:18:45.361233Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:18:45.362897Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=672 output_len=0 content_len=672", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:45.363004Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.output_text", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:45.363121Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.output_text len=672", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:45.363234Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=672", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:45.363322Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:45.364713Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.output_text (schema=responses.output_text, route=responses)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:45.365123Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=1204 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:18:45.365358Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=intro label=intro", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:18:45.365545Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=3695 attempt=1 max_tokens=1780", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:18:46.020385Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:18:46.021509Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1780 (requested=1780, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:46.021623Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESPONSES_PARAM_OMITTED omitted=['temperature'] model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:46.022441Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:46.022549Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:46.022618Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3771", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:46.022675Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:46.022731Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:18:48.008347Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:18:48] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:18:53.009162Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:18:53] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:18:58.008577Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:18:58] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:19:03.009681Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:19:03] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:19:05.783963Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:19:05.785393Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:05.785499Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:05.785642Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:05.785737Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:05.785835Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1780 to=2670 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:05.785969Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_059b3e46f17ba56b0068fb7cb631fc8196848550cb49c6a0b7", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:05.786098Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:05.786212Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:05.786287Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3771", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:05.786356Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:05.786423Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:08.009945Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:19:08] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:19:13.009254Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:19:13] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:19:18.008329Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:19:18] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:19:23.009141Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:19:23] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:19:28.009064Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:19:28] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:19:33.008644Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:19:33] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:19:38.009326Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:19:38] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:19:43.008823Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:19:43] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:19:48.009655Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:19:48] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:19:52.168974Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:19:52.170374Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:52.170479Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:52.170630Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:52.170725Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:52.170824Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2670 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:52.170962Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_059b3e46f17ba56b0068fb7cc9fa948196b1792aa1ced6b38f", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:52.171092Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:52.171207Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:52.171289Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3771", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:52.171377Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:52.171434Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:19:53.010229Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:19:53] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:19:58.010279Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:19:58] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:20:03.009374Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:20:03] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:20:08.009789Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:20:08] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:20:13.013826Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:20:13] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:20:18.007708Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:20:18] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:20:22.013542Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:20:22] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:20:26.019876Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:20:26] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:20:30.024505Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:20:30] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:20:30.163072Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:20:30.164620Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:30.164727Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:30.164863Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:30.164959Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:30.165064Z", "level": "WARNING", "logger": "llm_client", "message": "LLM_WARN cap_reached limit=3600 output_len=0 content_len=0 status=incomplete reason=max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:30.165170Z", "level": "WARNING", "logger": "llm_client", "message": "LLM_WARN cap_reached limit=3600 status=incomplete reason=max_output_tokens_final", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:30.165628Z", "level": "WARNING", "logger": "llm_client", "message": "parse_chain: content_str=0; parts=0; content_dict=0; choices_text=0; output_text=0; retry=0; fallback=responses; schema=unknown", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:30.165707Z", "level": "WARNING", "logger": "llm_client", "message": "empty completion from Responses API gpt-5 (schema=unknown)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:30.165776Z", "level": "WARNING", "logger": "llm_client", "message": "switching to fallback model gpt-4o (primary=gpt-5, reason=empty_completion_gpt5_responses)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:30.165833Z", "level": "INFO", "logger": "llm_client", "message": "chat payload: tool_choice omitted (no tools)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:30.165893Z", "level": "INFO", "logger": "llm_client", "message": "openai payload blueprint: {'model': 'gpt-4o', 'messages': '<3 messages>', 'max_tokens': 1780, 'temperature': 0.3}", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:30.165955Z", "level": "INFO", "logger": "llm_client", "message": "dispatch route=chat model=gpt-4o", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:34.030448Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:20:34] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:20:38.035807Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:20:38] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:20:42.044382Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:20:42] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:20:45.837805Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:20:45.839662Z", "level": "INFO", "logger": "llm_client", "message": "fallback completion schema category=text (schema=message.content:str, route=chat)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:45.840002Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=unknown status=ok", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:20:45.840236Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=main label=main[1]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:20:45.840344Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:SCHEDULER_BLOCK main underflow=1 target_min=3 → continue_main", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:20:45.840450Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:SCHEDULER_BLOCK main underflow=1 target_min=3 → continue_main", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:20:45.840527Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:SCHEDULER_BLOCK main underflow=1 target_min=3 → continue_main", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:20:45.840693Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=3772 attempt=1 max_tokens=1780", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:20:46.049799Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:20:46] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:20:46.372756Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:20:46.373835Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1780 (requested=1780, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:46.373945Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESPONSES_PARAM_OMITTED omitted=['temperature'] model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:46.374734Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:46.374886Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:46.374954Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3848", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:46.375010Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:46.375064Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:20:50.055185Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:20:50] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:20:54.060916Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:20:54] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:20:58.066516Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:20:58] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:21:03.008697Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:21:03] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:21:06.891482Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:21:06.892589Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:06.892672Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:06.892783Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:06.892860Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:06.892937Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1780 to=2670 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:06.893046Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_048e09ea98012eae0068fb7d2ea2c0819b980b277ee6526bd7", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:06.893157Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:06.893251Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:06.893316Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3848", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:06.893381Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:06.893438Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:08.009359Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:21:08] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:21:13.008939Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:21:13] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:21:18.009567Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:21:18] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:21:23.010325Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:21:23] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:21:28.008410Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:21:28] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:21:33.009719Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:21:33] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:21:38.009519Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:21:38] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:21:43.009863Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:21:43] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:21:45.014288Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:21:45.015328Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:45.015403Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:45.015500Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:45.015565Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:45.015636Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2670 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:45.015732Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_048e09ea98012eae0068fb7d431b60819ba2b531a2a23862f2", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:45.015826Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:45.015907Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:45.015961Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3848", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:45.016007Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:45.016054Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:21:48.008391Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:21:48] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:21:53.008861Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:21:53] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:21:58.009400Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:21:58] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:22:03.009986Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:22:03] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:22:07.014976Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:22:07] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:22:12.008631Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:22:12] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:22:16.013209Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:22:16] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:22:21.009033Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:22:21] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:22:23.036282Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:22:23.037947Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:23.038073Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:23.038322Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:23.038426Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:23.038531Z", "level": "WARNING", "logger": "llm_client", "message": "LLM_WARN cap_reached limit=3600 output_len=0 content_len=0 status=incomplete reason=max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:23.038619Z", "level": "WARNING", "logger": "llm_client", "message": "LLM_WARN cap_reached limit=3600 status=incomplete reason=max_output_tokens_final", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:23.039600Z", "level": "WARNING", "logger": "llm_client", "message": "parse_chain: content_str=0; parts=0; content_dict=0; choices_text=0; output_text=0; retry=0; fallback=responses; schema=unknown", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:23.039729Z", "level": "WARNING", "logger": "llm_client", "message": "empty completion from Responses API gpt-5 (schema=unknown)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:23.040025Z", "level": "WARNING", "logger": "llm_client", "message": "switching to fallback model gpt-4o (primary=gpt-5, reason=empty_completion_gpt5_responses)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:23.040133Z", "level": "INFO", "logger": "llm_client", "message": "chat payload: tool_choice omitted (no tools)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:23.040221Z", "level": "INFO", "logger": "llm_client", "message": "openai payload blueprint: {'model': 'gpt-4o', 'messages': '<3 messages>', 'max_tokens': 1780, 'temperature': 0.3}", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:23.040304Z", "level": "INFO", "logger": "llm_client", "message": "dispatch route=chat model=gpt-4o", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:26.008719Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:22:26] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:22:30.014452Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:22:30] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:22:32.157924Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:22:32.164283Z", "level": "INFO", "logger": "llm_client", "message": "fallback completion schema category=text (schema=message.content:str, route=chat)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:32.164586Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=unknown status=ok", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:22:32.164803Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=main label=main[2-3]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:22:32.164977Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=3699 attempt=1 max_tokens=1780", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:22:32.902308Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:22:32.903164Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1780 (requested=1780, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:32.903252Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESPONSES_PARAM_OMITTED omitted=['temperature'] model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:32.903815Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:32.903905Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:32.903980Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3775", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:32.904079Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:32.904135Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:35.009217Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:22:35] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:22:39.015249Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:22:39] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:22:43.020813Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:22:43] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:22:48.009713Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:22:48] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:22:53.009556Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:22:53] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:22:53.406237Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:22:53.407605Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:53.407689Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:53.407820Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:53.407898Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:53.407977Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1780 to=2670 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:53.408084Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0a8c105bdade94ff0068fb7d992f2c819a97e20b15c365ffdb", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:53.408187Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:53.408277Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:53.408339Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3775", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:53.408394Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:53.408448Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:22:58.010833Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:22:58] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:23:03.009464Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:23:03] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:23:08.011208Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:23:08] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:23:13.009179Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:23:13] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:23:18.010043Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:23:18] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:23:23.008717Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:23:23] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:23:27.404036Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:23:27.405373Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:23:27.405477Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:23:27.405610Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:23:27.405703Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:23:27.405803Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2670 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:23:27.405939Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0a8c105bdade94ff0068fb7dad9d0c819a850260af347276d7", "name": "llm_client"}
{"timestamp": "2025-10-24T13:23:27.406064Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:23:27.406179Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:23:27.406319Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3775", "name": "llm_client"}
{"timestamp": "2025-10-24T13:23:27.406435Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:23:27.406520Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:23:28.010075Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:23:28] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:23:33.009855Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:23:33] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:23:38.009827Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:23:38] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:23:43.009024Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:23:43] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:23:48.010798Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:23:48] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:23:53.009560Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:23:53] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:23:58.010606Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:23:58] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:24:03.010766Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:24:03] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:24:06.935266Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:24:07.119949Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=2855 output_len=0 content_len=2855", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:07.120033Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.output_text", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:07.120105Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.output_text len=2855", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:07.120177Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=2855", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:07.120234Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:07.120889Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.output_text (schema=responses.output_text, route=responses)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:07.121149Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=3345 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:24:07.121307Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=faq label=faq[1-3]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:24:07.121449Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=3699 attempt=1 max_tokens=1780", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:24:07.619569Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:24:07.620229Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1780 (requested=1780, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:07.620296Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESPONSES_PARAM_OMITTED omitted=['temperature'] model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:07.620766Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:07.620845Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:07.620894Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3775", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:07.620936Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:07.620977Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:08.010371Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:24:08] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:24:13.008998Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:24:13] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:24:18.010648Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:24:18] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:24:23.010551Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:24:23] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:24:28.009546Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:24:28] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:24:31.094347Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:24:31.095938Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1392 output_len=0 content_len=1392", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:31.096058Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.output_text", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:31.096232Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.output_text len=1392", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:31.096330Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=1392", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:31.096393Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:31.096451Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:31.096559Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1780 to=2670 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:31.096658Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0cf0ea184ba161830068fb7df7d1e081999bc33cd7cdd2c394", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:31.096746Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:31.096823Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:31.096876Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3775", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:31.096920Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:31.096966Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:33.012763Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:24:33] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:24:38.010016Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:24:38] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:24:43.010361Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:24:43] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:24:45.731444Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:24:45.733294Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1971 output_len=0 content_len=1971", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:45.733399Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.output_text", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:45.733509Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.output_text len=1971", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:45.733624Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:45.734379Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.output_text (schema=responses.output_text, route=responses)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:45.734693Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=1251 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:24:45.734860Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=faq label=faq[4-5]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:24:45.735016Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=3613 attempt=1 max_tokens=1780", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:24:46.687612Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:24:46.688310Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1780 (requested=1780, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:46.688390Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESPONSES_PARAM_OMITTED omitted=['temperature'] model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:46.688871Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:46.688950Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:46.689004Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3689", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:46.689050Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:46.689094Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:24:48.010125Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:24:48] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:24:52.016258Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:24:52] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:24:57.010468Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:24:57] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:25:02.009906Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:25:02] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:25:07.011577Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:25:07] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:25:11.152950Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:25:11.154775Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1792 output_len=0 content_len=1792", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:11.154883Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.output_text", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:11.154992Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.output_text len=1792", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:11.155112Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=1792", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:11.155182Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:11.155861Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.output_text (schema=responses.output_text, route=responses)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:11.156167Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=1327 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:25:11.156312Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=conclusion label=conclusion", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:25:11.156420Z", "level": "INFO", "logger": "skeleton_utils", "message": "LOG:SKELETON_NORMALIZED keys=intro,main[],faq[],conclusion", "name": "skeleton_utils"}
{"timestamp": "2025-10-24T13:25:11.156850Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "SKELETON_OK route=responses", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:25:11.160008Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "KEYWORDS_COVERAGE=100% missing=-", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:25:11.160127Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "KEYWORDS_OK coverage=100.00%", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:25:11.160847Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "FAQ_OK entries=№1. Как выбрать кредитную карту для повседневных трат семьи?,№2. Как пользоваться кредиткой, чтобы не переплачивать и не уходить в минус?,№3. Как сравнить предложения и посчитать реальную стоимость обслуживания?,№4. Что важно знать о льготном периоде, чтобы не потерять его преимущества?,№5. Как повысить шанс одобрения и выбрать безопасный кредитный лимит?", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:25:11.182277Z", "level": "WARNING", "logger": "content_factory.pipeline", "message": "TRIM_LEN_RELAXED length=6831 range=3500-6000 soft_range=3430-6120", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:25:11.186211Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "SKELETON_ESTIMATE predicted=1484 start_max=1780 cap=3600 → resolved max_output_tokens=1780", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:25:11.186426Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=3781 attempt=1 max_tokens=1780", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:25:12.010129Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:25:12] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:25:12.499152Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:25:12.500399Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1780 (requested=1780, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:12.500497Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESPONSES_PARAM_OMITTED omitted=['temperature'] model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:12.501123Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:12.501227Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:12.501294Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3857", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:12.501351Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:12.501406Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:17.010027Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:25:17] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:25:22.009243Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:25:22] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:25:27.010662Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:25:27] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:25:31.016056Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:25:31] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:25:33.503564Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:25:33.504934Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:33.505179Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:33.505382Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:33.505483Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:33.505579Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1780 to=2670 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:33.505702Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0363d43fb1774f8c0068fb7e38c468819895b11ca03a865e8a", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:33.505823Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:33.505928Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:33.505999Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3857", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:33.506061Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:33.506125Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:25:35.023100Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:25:35] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:25:39.029043Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:25:39] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:25:43.034108Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:25:43] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:25:47.042017Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:25:47] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:25:51.048010Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:25:51] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:25:56.010494Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:25:56] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:26:01.011143Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:26:01] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:26:03.271260Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:26:03.272471Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=556 output_len=0 content_len=556", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:03.272558Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.output_text", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:03.272632Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.output_text len=556", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:03.272761Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=556", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:03.272825Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:03.273325Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.output_text (schema=responses.output_text, route=responses)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:03.273645Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=1758 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:26:03.273822Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=intro label=intro", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:26:03.273984Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=3695 attempt=1 max_tokens=1780", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:26:04.044970Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:26:04.049281Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1780 (requested=1780, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:04.050019Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESPONSES_PARAM_OMITTED omitted=['temperature'] model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:04.050824Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:04.050964Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:04.051063Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3771", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:04.051183Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:04.051262Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:06.010997Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:26:06] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:26:11.009661Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:26:11] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:26:16.010375Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:26:16] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:26:21.010908Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:26:21] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:26:26.010878Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:26:26] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:26:29.057263Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:26:29.058527Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:29.058612Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:29.058717Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:29.058792Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:29.058868Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1780 to=2670 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:29.058976Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0217684054c9487e0068fb7e6c4a00819ab53acee6406236e2", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:29.059078Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:29.059171Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:29.059233Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3771", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:29.059286Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:29.059341Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:26:31.009294Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:26:31] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:26:36.009596Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:26:36] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:26:41.011721Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:26:41] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:26:46.011758Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:26:46] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:26:51.010852Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:26:51] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:26:56.008877Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:26:56] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:27:01.011034Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:27:01] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:27:01.617369Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:27:01.618713Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:01.618802Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:01.618909Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:01.618996Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:01.619077Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2670 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:01.619190Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0217684054c9487e0068fb7e853e3c819a864921c2f7fe12d4", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:01.619290Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:01.619382Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:01.619444Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3771", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:01.619499Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:01.619552Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:06.011102Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:27:06] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:27:11.009914Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:27:11] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:27:16.010431Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:27:16] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:27:21.010203Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:27:21] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:27:26.011460Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:27:26] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:27:31.009819Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:27:31] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:27:36.011461Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:27:36] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:27:40.865300Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:27:40.867034Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:40.867130Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:40.867241Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:40.867322Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:40.867401Z", "level": "WARNING", "logger": "llm_client", "message": "LLM_WARN cap_reached limit=3600 output_len=0 content_len=0 status=incomplete reason=max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:40.867483Z", "level": "WARNING", "logger": "llm_client", "message": "LLM_WARN cap_reached limit=3600 status=incomplete reason=max_output_tokens_final", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:40.867873Z", "level": "WARNING", "logger": "llm_client", "message": "parse_chain: content_str=0; parts=0; content_dict=0; choices_text=0; output_text=0; retry=0; fallback=responses; schema=unknown", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:40.867955Z", "level": "WARNING", "logger": "llm_client", "message": "empty completion from Responses API gpt-5 (schema=unknown)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:40.868026Z", "level": "WARNING", "logger": "llm_client", "message": "switching to fallback model gpt-4o (primary=gpt-5, reason=empty_completion_gpt5_responses)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:40.868083Z", "level": "INFO", "logger": "llm_client", "message": "chat payload: tool_choice omitted (no tools)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:40.868142Z", "level": "INFO", "logger": "llm_client", "message": "openai payload blueprint: {'model': 'gpt-4o', 'messages': '<3 messages>', 'max_tokens': 1780, 'temperature': 0.3}", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:40.868205Z", "level": "INFO", "logger": "llm_client", "message": "dispatch route=chat model=gpt-4o", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:41.011193Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:27:41] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:27:46.010864Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:27:46] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:27:51.011496Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:27:51] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:27:51.533366Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:27:51.538203Z", "level": "INFO", "logger": "llm_client", "message": "fallback completion schema category=text (schema=message.content:str, route=chat)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:51.538485Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=unknown status=ok", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:27:51.538647Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=main label=main[1]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:27:51.538721Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:SCHEDULER_BLOCK main underflow=1 target_min=3 → continue_main", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:27:51.538788Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:SCHEDULER_BLOCK main underflow=1 target_min=3 → continue_main", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:27:51.538928Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:SCHEDULER_BLOCK main underflow=1 target_min=3 → continue_main", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:27:51.539115Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=3772 attempt=1 max_tokens=1780", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:27:51.896603Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:27:51.897683Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1780 (requested=1780, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:51.897800Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESPONSES_PARAM_OMITTED omitted=['temperature'] model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:51.898687Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:51.898951Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:51.899028Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3848", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:51.899089Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:51.899146Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:27:56.011236Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:27:56] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:28:01.011506Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:28:01] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:28:06.011948Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:28:06] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:28:10.026531Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:28:10] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:28:14.101237Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:28:14.102675Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:14.102779Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:14.102918Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:14.103014Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:14.103109Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1780 to=2670 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:14.103245Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ee23889888850cc0068fb7ed819988198b282636659c7607e", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:14.103371Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:14.103486Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:14.103563Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3848", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:14.103645Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:14.103699Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:15.012119Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:28:15] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:28:20.015712Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:28:20] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:28:25.015904Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:28:25] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:28:30.017456Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:28:30] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:28:35.017483Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:28:35] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:28:40.017031Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:28:40] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:28:42.679334Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:28:42.680791Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:42.680889Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:42.680998Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:42.681091Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:42.681172Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2670 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:42.681284Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ee23889888850cc0068fb7eee514c81989250fd3267d29c49", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:42.681389Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:42.681485Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:42.681547Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3848", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:42.681602Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:42.681656Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:28:45.018667Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:28:45] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:28:50.019438Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:28:50] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:28:55.019154Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:28:55] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:28:59.024913Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:28:59] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:29:03.030435Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:29:03] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:29:07.035892Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:29:07] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:29:11.042664Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:29:11] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:29:15.048365Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:29:15] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:29:19.054515Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:29:19] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:29:23.060813Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:29:23] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:29:25.136130Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:29:25.141921Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:25.142018Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:25.142126Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:25.142202Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:25.142279Z", "level": "WARNING", "logger": "llm_client", "message": "LLM_WARN cap_reached limit=3600 output_len=0 content_len=0 status=incomplete reason=max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:25.142358Z", "level": "WARNING", "logger": "llm_client", "message": "LLM_WARN cap_reached limit=3600 status=incomplete reason=max_output_tokens_final", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:25.142741Z", "level": "WARNING", "logger": "llm_client", "message": "parse_chain: content_str=0; parts=0; content_dict=0; choices_text=0; output_text=0; retry=0; fallback=responses; schema=unknown", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:25.144220Z", "level": "WARNING", "logger": "llm_client", "message": "empty completion from Responses API gpt-5 (schema=unknown)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:25.144307Z", "level": "WARNING", "logger": "llm_client", "message": "switching to fallback model gpt-4o (primary=gpt-5, reason=empty_completion_gpt5_responses)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:25.144385Z", "level": "INFO", "logger": "llm_client", "message": "chat payload: tool_choice omitted (no tools)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:25.144436Z", "level": "INFO", "logger": "llm_client", "message": "openai payload blueprint: {'model': 'gpt-4o', 'messages': '<3 messages>', 'max_tokens': 1780, 'temperature': 0.3}", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:25.144491Z", "level": "INFO", "logger": "llm_client", "message": "dispatch route=chat model=gpt-4o", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:27.066964Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:29:27] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:29:31.073985Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:29:31] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:29:34.233559Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:29:34.235254Z", "level": "INFO", "logger": "llm_client", "message": "fallback completion schema category=text (schema=message.content:str, route=chat)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:34.235600Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=unknown status=ok", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:29:34.235800Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=main label=main[2-3]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:29:34.235962Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=3699 attempt=1 max_tokens=1780", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:29:34.858528Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:29:34.859581Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1780 (requested=1780, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:34.859691Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESPONSES_PARAM_OMITTED omitted=['temperature'] model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:34.860402Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:34.860513Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:34.860580Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3775", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:34.860637Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:34.860691Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:29:35.078750Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:29:35] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:29:39.083509Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:29:39] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:29:44.020200Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:29:44] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:29:48.867612Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:29:48] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:29:53.020288Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:29:53] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:29:58.020205Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:29:58] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:30:02.062874Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:30:02.064324Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:02.064430Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:02.064575Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:02.064672Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:02.064768Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1780 to=2670 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:02.064908Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_05de6c81e567ee530068fb7f3f12ac8198ac5a637d813bae74", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:02.065036Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:02.065149Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:02.065226Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3775", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:02.065297Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:02.065378Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:03.042974Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:30:03] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:30:08.020325Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:30:08] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:30:13.021318Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:30:13] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:30:18.022611Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:30:18] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:30:23.048772Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:30:23] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:30:28.021413Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:30:28] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:30:33.019427Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:30:33] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:30:37.824374Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:30:37.890951Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=2938 output_len=0 content_len=2938", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:37.891046Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.output_text", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:37.891197Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.output_text len=2938", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:37.891301Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=2938", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:37.891367Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:37.892038Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.output_text (schema=responses.output_text, route=responses)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:37.892386Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=2310 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:30:37.892557Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=faq label=faq[1-3]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:30:37.892703Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=3699 attempt=1 max_tokens=1780", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:30:38.021529Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:30:38] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:30:38.290398Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:30:38.291648Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1780 (requested=1780, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:38.291757Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESPONSES_PARAM_OMITTED omitted=['temperature'] model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:38.292521Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:38.292664Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:38.292731Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3775", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:38.292787Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:38.292840Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:30:43.021851Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:30:43] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:30:48.021664Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:30:48] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:30:53.021958Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:30:53] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:30:58.022012Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:30:58] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:31:02.028494Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:31:02] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:31:05.131134Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:31:05.132514Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:05.132598Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:05.132705Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:05.132781Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:05.132857Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1780 to=2670 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:05.132972Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0b4c2ca504ae2fe00068fb7f7e7608819b9a943858e7c02bbd", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:05.133086Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:05.133180Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:05.133241Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3775", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:05.133296Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:05.133351Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:07.021943Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:31:07] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:31:12.019992Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:31:12] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:31:17.021059Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:31:17] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:31:22.020832Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:31:22] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:31:27.020806Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:31:27] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:31:32.020587Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:31:32] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:31:37.021164Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:31:37] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:31:41.964063Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:31:41.965516Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:41.965621Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:41.965757Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:41.965852Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:41.965949Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2670 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:41.966086Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0b4c2ca504ae2fe00068fb7f99d38c819b80a77d0c9212b579", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:41.966214Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:41.966330Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:41.966428Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3775", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:41.966485Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:41.966539Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:31:42.021777Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:31:42] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:31:47.021300Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:31:47] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:31:51.026026Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:31:51] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:31:56.022406Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:31:56] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:32:01.020457Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:32:01] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:32:05.024778Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:32:05] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:32:09.029107Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:32:09] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:32:15.054269Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:32:15] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:32:19.058420Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:32:19] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:32:24.022466Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:32:24] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:32:29.029095Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:32:29] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:32:32.288584Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:32:32.294466Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:32.294568Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:32.294678Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:32.294755Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:32.294831Z", "level": "WARNING", "logger": "llm_client", "message": "LLM_WARN cap_reached limit=3600 output_len=0 content_len=0 status=incomplete reason=max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:32.294910Z", "level": "WARNING", "logger": "llm_client", "message": "LLM_WARN cap_reached limit=3600 status=incomplete reason=max_output_tokens_final", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:32.295889Z", "level": "WARNING", "logger": "llm_client", "message": "parse_chain: content_str=0; parts=0; content_dict=0; choices_text=0; output_text=0; retry=0; fallback=responses; schema=unknown", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:32.295989Z", "level": "WARNING", "logger": "llm_client", "message": "empty completion from Responses API gpt-5 (schema=unknown)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:32.296063Z", "level": "WARNING", "logger": "llm_client", "message": "switching to fallback model gpt-4o (primary=gpt-5, reason=empty_completion_gpt5_responses)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:32.296123Z", "level": "INFO", "logger": "llm_client", "message": "chat payload: tool_choice omitted (no tools)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:32.296183Z", "level": "INFO", "logger": "llm_client", "message": "openai payload blueprint: {'model': 'gpt-4o', 'messages': '<3 messages>', 'max_tokens': 1780, 'temperature': 0.3}", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:32.296249Z", "level": "INFO", "logger": "llm_client", "message": "dispatch route=chat model=gpt-4o", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:34.030771Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:32:34] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:32:37.328548Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:32:37.342518Z", "level": "INFO", "logger": "llm_client", "message": "fallback completion schema category=text (schema=message.content:str, route=chat)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:37.342952Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=unknown status=ok", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:32:37.343161Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=faq label=faq[4-5]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:32:37.343346Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=3613 attempt=1 max_tokens=1780", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:32:38.112276Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:32:38.113182Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1780 (requested=1780, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:38.113293Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESPONSES_PARAM_OMITTED omitted=['temperature'] model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:38.114165Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:38.114307Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:38.114454Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3689", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:38.114602Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:38.114691Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:39.021114Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:32:39] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:32:44.019977Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:32:44] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:32:49.020280Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:32:49] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:32:54.022169Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:32:54] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:32:59.020777Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:32:59] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:32:59.851803Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:32:59.852945Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:59.853034Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:59.853142Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:59.853216Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1780", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:59.853297Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1780 to=2670 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:59.853501Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0f14e020c764d3f80068fb7ff64328819692e27cb29835a1e0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:59.853729Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:59.853979Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:59.854091Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3689", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:59.854218Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:32:59.854375Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:33:04.022010Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:33:04] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:33:09.021752Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:33:09] \"GET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:33:14.021641Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:33:14] \"\u001b[33mGET /api/jobs/1bcb55179c6e41b2ad9933ae25fb339b HTTP/1.1\u001b[0m\" 404 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:33:54.658930Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:33:54.662589Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1851 output_len=0 content_len=1851", "name": "llm_client"}
{"timestamp": "2025-10-24T13:33:54.662771Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.output_text", "name": "llm_client"}
{"timestamp": "2025-10-24T13:33:54.662879Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.output_text len=1851", "name": "llm_client"}
{"timestamp": "2025-10-24T13:33:54.662987Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=1851", "name": "llm_client"}
{"timestamp": "2025-10-24T13:33:54.663059Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:33:54.663132Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2670", "name": "llm_client"}
{"timestamp": "2025-10-24T13:33:54.663279Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2670 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:33:54.663393Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0f14e020c764d3f80068fb800c35a88196a94e65746f39f805", "name": "llm_client"}
{"timestamp": "2025-10-24T13:33:54.663502Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:33:54.663779Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:33:54.663874Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3689", "name": "llm_client"}
{"timestamp": "2025-10-24T13:33:54.663936Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:33:54.663993Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:34:51.064783Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:34:51.069017Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=5467 output_len=0 content_len=5467", "name": "llm_client"}
{"timestamp": "2025-10-24T13:34:51.069156Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.output_text", "name": "llm_client"}
{"timestamp": "2025-10-24T13:34:51.069276Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.output_text len=5467", "name": "llm_client"}
{"timestamp": "2025-10-24T13:34:51.069383Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-24T13:34:51.071647Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.output_text (schema=responses.output_text, route=responses)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:34:51.072120Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=1867 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:34:51.072370Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=conclusion label=conclusion", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:34:51.072500Z", "level": "INFO", "logger": "skeleton_utils", "message": "LOG:SKELETON_NORMALIZED keys=intro,main[],faq[],conclusion", "name": "skeleton_utils"}
{"timestamp": "2025-10-24T13:34:51.072930Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "SKELETON_OK route=responses", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:34:51.075615Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "KEYWORDS_COVERAGE=100% missing=-", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:34:51.075694Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "KEYWORDS_OK coverage=100.00%", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:34:51.076674Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "FAQ_OK entries=1. Как понять, подходит ли кредитная карта молодой семье для повседневных расходов?,2. Что важнее: льготный период или кэшбэк — и как извлечь максимум выгоды?,3. Как посчитать реальную стоимость кредитки с учётом комиссий и бонусов?,4. Как безопасно пользоваться кредитной картой и не уйти в долг?,5. На какие тарифные пункты и мелкий шрифт смотреть в первую очередь?", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:34:51.105502Z", "level": "WARNING", "logger": "content_factory.pipeline", "message": "TRIM_LEN_RELAXED length=10687 range=3500-6000 soft_range=3430-6120", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:34:51.108006Z", "level": "INFO", "logger": "content_factory.jobs.runner", "message": "job_step", "name": "content_factory.jobs.runner", "job_id": "1bcb55179c6e41b2ad9933ae25fb339b", "step": "draft", "step_status": "degraded", "details": {"error": "После тримминга потеряны ключевые фразы: Банки, деньги, карты, кредиты", "payload": {"attempts": 2, "error": "После тримминга потеряны ключевые фразы: Банки, деньги, карты, кредиты"}}}
{"timestamp": "2025-10-24T13:34:51.108254Z", "level": "INFO", "logger": "content_factory.jobs.runner", "message": "job_step", "name": "content_factory.jobs.runner", "job_id": "1bcb55179c6e41b2ad9933ae25fb339b", "step": "refine", "step_status": "degraded", "details": {"reason": "soft_timeout"}}
{"timestamp": "2025-10-24T13:35:18.614668Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:35:18] \"GET /api/artifacts/download?path=2025-10-24_1334_finance_article.md HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:35:31.252111Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:35:31] \"GET /api/artifacts/download?path=2025-10-24_1334_finance_article.json HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:35:32.355090Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:35:32] \"\u001b[36mGET /api/artifacts/download?path=2025-10-24_1334_finance_article.md HTTP/1.1\u001b[0m\" 304 -", "name": "werkzeug"}
^C^C
(venv) ivan@Device115 contentfabric % 
(venv) ivan@Device115 contentfabric % rm 1.txt
(venv) ivan@Device115 contentfabric % nano 1.txt
(venv) ivan@Device115 contentfabric % git apply 1.txt 
(venv) ivan@Device115 contentfabric % git add .       
(venv) ivan@Device115 contentfabric % git commit -m " 
1Fix system failures during SEO article generation123"

[main 3cb4711] 1Fix system failures during SEO article generation123
 9 files changed, 1354 insertions(+), 1848 deletions(-)
(venv) ivan@Device115 contentfabric % git push        
Enumerating objects: 25, done.
Counting objects: 100% (25/25), done.
Delta compression using up to 12 threads
Compressing objects: 100% (13/13), done.
Writing objects: 100% (13/13), 16.62 KiB | 5.54 MiB/s, done.
Total 13 (delta 11), reused 0 (delta 0), pack-reused 0 (from 0)
remote: Resolving deltas: 100% (11/11), completed with 10 local objects.
To https://github.com/safeiris/content.git
   f615394..3cb4711  main -> main
(venv) ivan@Device115 contentfabric % python -m server

{"timestamp": "2025-10-24T13:42:34.944836Z", "level": "WARNING", "logger": "content_factory.api", "message": "FLASK_SECRET_KEY is not set; generating a temporary secret key", "name": "content_factory.api"}
{"timestamp": "2025-10-24T13:42:34.954948Z", "level": "WARNING", "logger": "content_factory.api", "message": "FLASK_SECRET_KEY is not set; generating a temporary secret key", "name": "content_factory.api"}
✅ Server running: UI + API on http://127.0.0.1:8000
 * Serving Flask app 'server'
 * Debug mode: off
{"timestamp": "2025-10-24T13:42:34.966954Z", "level": "INFO", "logger": "werkzeug", "message": "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n * Running on http://127.0.0.1:8000", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:42:34.967045Z", "level": "INFO", "logger": "werkzeug", "message": "\u001b[33mPress CTRL+C to quit\u001b[0m", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:42:39.372458Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:42:39] \"\u001b[32mGET / HTTP/1.1\u001b[0m\" 302 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:42:39.382277Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:42:39] \"GET /login?next=/ HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:42:39.597743Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:42:39] \"\u001b[32mGET /favicon.ico HTTP/1.1\u001b[0m\" 302 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:42:39.611354Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:42:39] \"GET /login?next=/favicon.ico HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:42:43.280305Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:42:43] \"\u001b[32mPOST /login?next=/ HTTP/1.1\u001b[0m\" 302 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:42:43.289139Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:42:43] \"GET / HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:42:43.307533Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:42:43] \"\u001b[36mGET /styles.css HTTP/1.1\u001b[0m\" 304 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:42:43.311495Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:42:43] \"\u001b[36mGET /script.js HTTP/1.1\u001b[0m\" 304 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:42:43.359632Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:42:43] \"GET /api/pipes HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:42:43.434843Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:42:43] \"GET /favicon.ico HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:42:43.439627Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:42:43] \"GET /api/artifacts HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:42:44.482087Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "trace_id": "d4af221087324fe997320b43d228aeac", "name": "httpx"}
{"timestamp": "2025-10-24T13:42:44.845584Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 400 Bad Request\"", "trace_id": "d4af221087324fe997320b43d228aeac", "name": "httpx"}
{"timestamp": "2025-10-24T13:42:46.725008Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "trace_id": "d4af221087324fe997320b43d228aeac", "name": "httpx"}
{"timestamp": "2025-10-24T13:42:46.731324Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:42:46] \"GET /api/health?theme=finance HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:43:30.264991Z", "level": "INFO", "logger": "content_factory.jobs.runner", "message": "job_enqueued", "trace_id": "957b04fe45c24e42a7111a15cc572c1c", "name": "content_factory.jobs.runner", "job_id": "cbaa53b76dea4e8c86b3ec5150ba4806"}
{"timestamp": "2025-10-24T13:43:30.265736Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:43:30] \"\u001b[35m\u001b[1mPOST /api/generate HTTP/1.1\u001b[0m\" 202 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:43:30.870721Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:43:30] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:43:31.165725Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:43:31.398447Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 400 Bad Request\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:43:32.026801Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:43:32] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:43:32.376250Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:43:32.381034Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "SKELETON_ESTIMATE predicted=1484 start_max=1200 cap=3600 → resolved max_output_tokens=1200", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:43:32.381371Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=3776 attempt=1 max_tokens=1200", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:43:33.318535Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:43:33.323178Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1200 (requested=1200, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:33.323282Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESPONSES_PARAM_OMITTED omitted=['temperature'] model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:33.323920Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:33.324034Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:33.324167Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3852", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:33.324231Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1200", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:33.324290Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:34.025455Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:43:34] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:43:36.025143Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:43:36] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:43:38.025452Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:43:38] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:43:41.026040Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:43:41] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:43:44.081678Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:43:44] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:43:46.658899Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 500 Internal Server Error\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:43:46.659547Z", "level": "ERROR", "logger": "llm_client", "message": "Responses API error: status=500 error.type=server_error error.message=\"An error occurred while processing your request. You can retry your request, or contact us through our help center at help.openai.com if the error persists. Please include the request ID req_8c64b13c8\" step=skeleton", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:46.661341Z", "level": "WARNING", "logger": "llm_client", "message": "Responses API call failed: Ошибка сервиса OpenAI: HTTP 500 — An error occurred while processing your request. You can retry your request, or contact us through our help center at help.openai.com if the error persists. Please include the request ID req_8c64b13c838044bc9801d919c99aba72 in your message.", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:46.661482Z", "level": "WARNING", "logger": "llm_client", "message": "switching route to chat for model gpt-5 (reason=api_error_gpt5_responses)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:46.661632Z", "level": "INFO", "logger": "llm_client", "message": "chat payload: tool_choice omitted (no tools)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:46.661724Z", "level": "INFO", "logger": "llm_client", "message": "openai payload blueprint: {'model': 'gpt-5', 'messages': '<3 messages>', 'max_tokens': 1200, 'temperature': 0.3}", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:46.661790Z", "level": "INFO", "logger": "llm_client", "message": "dispatch route=chat model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:48.027617Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:43:48] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:43:50.956821Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:43:50.957161Z", "level": "WARNING", "logger": "llm_client", "message": "retry=shim_unknown_param: stripped 'max_tokens' from payload", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:51.179585Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:43:51.180185Z", "level": "ERROR", "logger": "content_factory.pipeline", "message": "LOG:LLM_ERROR step=skeleton message=Ошибка сервиса OpenAI: HTTP 400 — Unsupported value: 'temperature' does not support 0.3 with this model. Only the default (1) value is supported.", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:43:51.625532Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:43:52.315820Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 400 Bad Request\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:43:53.025233Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:43:53] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:43:53.693409Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:43:53.695026Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "SKELETON_ESTIMATE predicted=1484 start_max=1200 cap=3600 → resolved max_output_tokens=1200", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:43:53.695359Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=3776 attempt=1 max_tokens=1200", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:43:54.069036Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:43:54.070332Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1200 (requested=1200, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:54.070454Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESPONSES_PARAM_OMITTED omitted=['temperature'] model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:54.071207Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:54.071312Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:54.071383Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3852", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:54.071442Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1200", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:54.071499Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:43:58.025803Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:43:58] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:44:03.025174Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:44:03] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:44:07.721199Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:44:07.722628Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:07.722736Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:07.722885Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:07.722982Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1200", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:07.723089Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1200 to=1500 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:07.723231Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0e851a30223b4c710068fb829a3f508198b009972185aaa38b", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:07.723361Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:07.723470Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:07.723549Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3852", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:07.723640Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1500", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:07.723698Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:08.026217Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:44:08] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:44:13.026184Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:44:13] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:44:18.027051Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:44:18] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:44:23.024789Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:44:23] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:44:28.025427Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:44:28] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:44:32.537963Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:44:32.539425Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=277 output_len=0 content_len=277", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:32.539530Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.output_text", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:32.539647Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.output_text len=277", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:32.539756Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=277", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:32.539841Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:32.539925Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1500", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:32.540070Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1500 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:32.540200Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0e851a30223b4c710068fb82a7e2c881989b57cae464e98e21", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:32.540348Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:32.540440Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:32.540502Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3852", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:32.540558Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:32.540615Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:33.025645Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:44:33] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:44:38.027035Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:44:38] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:44:43.026509Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:44:43] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:44:46.958531Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:44:46.960025Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=501 output_len=0 content_len=501", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:46.960131Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.output_text", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:46.960239Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.output_text len=501", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:46.960355Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:46.961037Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.output_text (schema=responses.output_text, route=responses)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:46.961339Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=785 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:44:46.961535Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=intro label=intro", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:44:46.961701Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=3690 attempt=1 max_tokens=1200", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:44:47.735455Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:44:47.736367Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1200 (requested=1200, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:47.736456Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESPONSES_PARAM_OMITTED omitted=['temperature'] model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:47.737075Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:47.737183Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:47.737252Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3766", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:47.737309Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1200", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:47.737367Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:48.025889Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:44:48] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:44:53.029230Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:44:53] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:44:57.035246Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:44:57] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:44:58.965628Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:44:58.983772Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:58.983883Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:58.984859Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:58.985057Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1200", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:58.985241Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1200 to=1500 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:58.985436Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_07ac2cd3069c88920068fb82d00ca88198953af25c42ae464f", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:58.985620Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:58.985829Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:58.986836Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3766", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:58.987662Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1500", "name": "llm_client"}
{"timestamp": "2025-10-24T13:44:58.987828Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:02.025631Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:45:02] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:45:07.026648Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:45:07] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:45:12.027679Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:45:12] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:45:17.025283Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:45:17] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:45:22.027159Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:45:22] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:45:23.991521Z", "level": "WARNING", "logger": "llm_client", "message": "responses retry attempt=2 sleep=1.00", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:24.993533Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_07ac2cd3069c88920068fb82d00ca88198953af25c42ae464f", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:24.993843Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:24.994533Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:24.994632Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3766", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:24.994708Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1500", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:24.994786Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:27.027983Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:45:27] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:45:32.025971Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:45:32] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:45:37.027164Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:45:37] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:45:39.782880Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:45:39.784272Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:39.784377Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'temperature', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:39.784530Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:39.784637Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1500", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:39.784772Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1500 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:39.784914Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_07ac2cd3069c88920068fb82f539548198b292508b730f5a58", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:39.785053Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:39.785194Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:39.785258Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3766", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:39.785316Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:39.785372Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:45:42.028185Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:45:42] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:45:47.028756Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:45:47] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:45:52.028589Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:45:52] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:45:57.028329Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:45:57] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:46:02.029087Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:46:02] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:46:04.787629Z", "level": "WARNING", "logger": "llm_client", "message": "responses retry attempt=4 sleep=2.00", "name": "llm_client"}
{"timestamp": "2025-10-24T13:46:06.792056Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_07ac2cd3069c88920068fb82f539548198b292508b730f5a58", "name": "llm_client"}
{"timestamp": "2025-10-24T13:46:06.792258Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:46:06.792394Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:46:06.792477Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3766", "name": "llm_client"}
{"timestamp": "2025-10-24T13:46:06.792548Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:46:06.792617Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:46:07.031254Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:46:07] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:46:12.025748Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:46:12] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:46:17.026883Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:46:17] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:46:22.026805Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:46:22] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:46:27.026786Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:46:27] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:46:31.933407Z", "level": "WARNING", "logger": "llm_client", "message": "responses retry attempt=5 sleep=2.00", "name": "llm_client"}
{"timestamp": "2025-10-24T13:46:32.027116Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:46:32] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:46:33.935558Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_07ac2cd3069c88920068fb82f539548198b292508b730f5a58", "name": "llm_client"}
{"timestamp": "2025-10-24T13:46:33.935852Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:46:33.936063Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:46:33.936196Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3766", "name": "llm_client"}
{"timestamp": "2025-10-24T13:46:33.936300Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:46:33.936376Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:46:37.028734Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:46:37] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:46:42.027084Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:46:42] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:46:47.028706Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:46:47] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:46:52.027850Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:46:52] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:46:57.026077Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:46:57] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:46:59.003019Z", "level": "WARNING", "logger": "llm_client", "message": "responses retry attempt=6 sleep=2.00", "name": "llm_client"}
{"timestamp": "2025-10-24T13:47:01.008008Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_07ac2cd3069c88920068fb82f539548198b292508b730f5a58", "name": "llm_client"}
{"timestamp": "2025-10-24T13:47:01.008312Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:47:01.008558Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-24T13:47:01.008654Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=3766", "name": "llm_client"}
{"timestamp": "2025-10-24T13:47:01.008735Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-24T13:47:01.008812Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-24T13:47:02.031636Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:47:02] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:47:07.040654Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:47:07] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:47:12.026347Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:47:12] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:47:16.247955Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:47:16] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:47:20.265594Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:47:20] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:47:25.026980Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:47:25] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:47:26.279675Z", "level": "WARNING", "logger": "llm_client", "message": "Responses API call failed: Сетевой таймаут при обращении к модели. Проверьте соединение и повторите попытку.", "name": "llm_client"}
{"timestamp": "2025-10-24T13:47:26.279813Z", "level": "WARNING", "logger": "llm_client", "message": "switching route to chat for model gpt-5 (reason=api_error_gpt5_responses)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:47:26.279885Z", "level": "INFO", "logger": "llm_client", "message": "chat payload: tool_choice omitted (no tools)", "name": "llm_client"}
{"timestamp": "2025-10-24T13:47:26.279958Z", "level": "INFO", "logger": "llm_client", "message": "openai payload blueprint: {'model': 'gpt-5', 'messages': '<3 messages>', 'max_tokens': 1200, 'temperature': 0.3}", "name": "llm_client"}
{"timestamp": "2025-10-24T13:47:26.280029Z", "level": "INFO", "logger": "llm_client", "message": "dispatch route=chat model=gpt-5", "name": "llm_client"}
{"timestamp": "2025-10-24T13:47:27.509493Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:47:27.509958Z", "level": "WARNING", "logger": "llm_client", "message": "retry=shim_unknown_param: stripped 'max_tokens' from payload", "name": "llm_client"}
{"timestamp": "2025-10-24T13:47:28.330491Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"", "name": "httpx"}
{"timestamp": "2025-10-24T13:47:28.331162Z", "level": "ERROR", "logger": "content_factory.pipeline", "message": "LOG:LLM_ERROR step=skeleton message=Ошибка сервиса OpenAI: HTTP 400 — Unsupported value: 'temperature' does not support 0.3 with this model. Only the default (1) value is supported.", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-24T13:47:28.331344Z", "level": "INFO", "logger": "content_factory.jobs.runner", "message": "job_step", "name": "content_factory.jobs.runner", "job_id": "cbaa53b76dea4e8c86b3ec5150ba4806", "step": "draft", "step_status": "degraded", "details": {"error": "Сбой при обращении к модели (skeleton): Ошибка сервиса OpenAI: HTTP 400 — Unsupported value: 'temperature' does not support 0.3 with this model. Only the default (1) value is supported.", "payload": {"attempts": 2, "error": "Сбой при обращении к модели (skeleton): Ошибка сервиса OpenAI: HTTP 400 — Unsupported value: 'temperature' does not support 0.3 with this model. Only the default (1) value is supported."}}}
{"timestamp": "2025-10-24T13:47:28.331479Z", "level": "INFO", "logger": "content_factory.jobs.runner", "message": "job_step", "name": "content_factory.jobs.runner", "job_id": "cbaa53b76dea4e8c86b3ec5150ba4806", "step": "refine", "step_status": "degraded", "details": {"reason": "soft_timeout"}}
{"timestamp": "2025-10-24T13:47:30.027024Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:47:30] \"GET /api/jobs/cbaa53b76dea4e8c86b3ec5150ba4806 HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-24T13:47:30.035470Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [24/Oct/2025 15:47:30] \"GET /api/artifacts HTTP/1.1\" 200 -", "name": "werkzeug"}
