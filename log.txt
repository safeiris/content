✅ Server running: UI + API on http://127.0.0.1:8000
 * Serving Flask app 'server'
 * Debug mode: off
{"timestamp": "2025-10-25T13:44:04.913584Z", "level": "INFO", "logger": "werkzeug", "message": "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n * Running on http://127.0.0.1:8000", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:44:04.913657Z", "level": "INFO", "logger": "werkzeug", "message": "\u001b[33mPress CTRL+C to quit\u001b[0m", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:44:09.341395Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:44:09] \"\u001b[32mGET / HTTP/1.1\u001b[0m\" 302 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:44:09.351984Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:44:09] \"GET /login?next=/ HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:44:09.571337Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:44:09] \"\u001b[32mGET /favicon.ico HTTP/1.1\u001b[0m\" 302 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:44:09.589135Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:44:09] \"GET /login?next=/favicon.ico HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:44:12.842886Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:44:12] \"\u001b[32mPOST /login?next=/ HTTP/1.1\u001b[0m\" 302 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:44:12.851454Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:44:12] \"GET / HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:44:12.875039Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:44:12] \"\u001b[36mGET /styles.css HTTP/1.1\u001b[0m\" 304 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:44:12.878838Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:44:12] \"GET /script.js HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:44:12.903484Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:44:12] \"GET /api/features HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:44:12.913201Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:44:12] \"GET /api/pipes HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:44:12.935059Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:44:12] \"GET /api/artifacts HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:44:13.017651Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:44:13] \"GET /favicon.ico HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:44:13.901159Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "trace_id": "8f21b98336f74ec2a7177bb133ca84bc", "name": "httpx"}
{"timestamp": "2025-10-25T13:44:13.901750Z", "level": "INFO", "logger": "orchestrate", "message": "responses input_len=25", "trace_id": "8f21b98336f74ec2a7177bb133ca84bc", "name": "orchestrate"}
{"timestamp": "2025-10-25T13:44:14.400988Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 400 Bad Request\"", "trace_id": "8f21b98336f74ec2a7177bb133ca84bc", "name": "httpx"}
{"timestamp": "2025-10-25T13:44:14.401281Z", "level": "INFO", "logger": "orchestrate", "message": "responses input_len=25", "trace_id": "8f21b98336f74ec2a7177bb133ca84bc", "name": "orchestrate"}
{"timestamp": "2025-10-25T13:44:16.143347Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "trace_id": "8f21b98336f74ec2a7177bb133ca84bc", "name": "httpx"}
{"timestamp": "2025-10-25T13:44:16.147713Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:44:16] \"GET /api/health?theme=finance HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:45:03.873509Z", "level": "INFO", "logger": "content_factory.jobs.runner", "message": "job_enqueued", "trace_id": "bd039101bdf64888a8b4127e2b36f4cb", "name": "content_factory.jobs.runner", "job_id": "488380b7c7ee418b94fe806d2d4d97b4"}
{"timestamp": "2025-10-25T13:45:03.874147Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:45:03] \"\u001b[35m\u001b[1mPOST /api/generate HTTP/1.1\u001b[0m\" 202 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:45:03.880430Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:45:03] \"GET /api/jobs/488380b7c7ee418b94fe806d2d4d97b4/stream HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:45:04.509963Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:45:04.510588Z", "level": "INFO", "logger": "orchestrate", "message": "responses input_len=25", "name": "orchestrate"}
{"timestamp": "2025-10-25T13:45:05.056426Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 400 Bad Request\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:45:05.056776Z", "level": "INFO", "logger": "orchestrate", "message": "responses input_len=25", "name": "orchestrate"}
{"timestamp": "2025-10-25T13:45:06.708905Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:45:06.713514Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "SKELETON_ESTIMATE predicted=1532 start_max=1915 cap=3600 → resolved max_output_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:45:06.713887Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4478 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:45:07.420804Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:45:07.421474Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:07.422159Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:07.422970Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:07.423180Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:07.423254Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4552", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:07.423317Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:07.423377Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:36.425001Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:45:36.426355Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:36.426466Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:36.426655Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:36.426820Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:36.426951Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1915 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:36.427101Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_023cf6130fb61d7c0068fcd463a3548199b7a94bd7561f5ddd model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:36.427283Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:36.427475Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:36.427557Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4552", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:36.427623Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T13:45:36.427687Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:03.971039Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:46:03.972474Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:03.972583Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:03.972739Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:03.972845Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:03.972962Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2280 to=3000 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:03.973097Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_023cf6130fb61d7c0068fcd4809c888199ad5f9e9f77be52b1 model=gpt-5 max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:03.973268Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:03.973466Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:03.973534Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4552", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:03.973592Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:03.973652Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:55.788128Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:46:55.789993Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=561 output_len=0 content_len=561", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:55.790103Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:55.790219Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=561", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:55.790335Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=561", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:55.790447Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:55.791790Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:55.791951Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=2740 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:46:55.792187Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=intro label=intro", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:46:55.792426Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4461 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:46:56.401840Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:46:56.402494Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:56.403222Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:56.404182Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:56.404462Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:56.404533Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4535", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:56.404592Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T13:46:56.404651Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:47:21.694826Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:47:21.696164Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T13:47:21.696272Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:47:21.696428Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T13:47:21.696533Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T13:47:21.696644Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1915 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:47:21.696784Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0589b8d57c0ea0950068fcd4d09dc4819988ac2ed6e731090e model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T13:47:21.696967Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:47:21.697172Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:47:21.697258Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4535", "name": "llm_client"}
{"timestamp": "2025-10-25T13:47:21.697316Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T13:47:21.697375Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:06.034319Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:48:06.035751Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:06.035859Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:06.036007Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:06.036108Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:06.036218Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2280 to=3000 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:06.036358Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0589b8d57c0ea0950068fcd4ea2a888199af53600036cbd2ea model=gpt-5 max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:06.036539Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:06.036741Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:06.036839Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4535", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:06.036899Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:06.036956Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:45.150196Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:48:45.151667Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:45.151773Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:45.151926Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:45.152030Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:45.152138Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=3000 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:45.152278Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0589b8d57c0ea0950068fcd516566c8199ad23647ddea6462d model=gpt-5 max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:45.152465Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:45.152667Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:45.152735Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4535", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:45.152793Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:48:45.152852Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:30.516474Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:49:30.569408Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=3038 output_len=0 content_len=3038", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:30.569527Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:30.569603Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=3038", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:30.569694Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=3038", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:30.569758Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:30.569823Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:30.569949Z", "level": "INFO", "logger": "llm_client", "message": "RESP_INCOMPLETE_ACCEPT text len=3038", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:30.570863Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:30.570977Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=3575 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:49:30.571322Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4500 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:49:30.923553Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:49:30.924202Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:30.924672Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:30.925535Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:30.925667Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:30.925753Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4574", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:30.925826Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:30.925897Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:59.290041Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:49:59.291527Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1109 output_len=0 content_len=1109", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:59.291634Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:59.291753Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=1109", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:59.291871Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=1109", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:59.291962Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:59.292568Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T13:49:59.292688Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=1408 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:49:59.292804Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "FALLBACK_ROUTE used=output_text kind=main label=main[1-2]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:49:59.292913Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:TAIL_FILL_FORCED reason=missing_content kind=main items=1", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:49:59.292983Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:MAIN_TAIL_FILL start missing=1", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:49:59.293123Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4335 attempt=1 max_tokens=600", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:50:00.211923Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:50:00.212671Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=600 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:00.213318Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=600 (requested=600, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:00.214226Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:00.214482Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:00.214553Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4409", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:00.214612Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:00.214671Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:08.711248Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:50:08.712593Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:08.712699Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:08.712853Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:08.712954Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:08.713064Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=600 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:08.713197Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0fc5cb64a2dc40350068fcd588938c8198bc529bf3cdc6e768 model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:08.713360Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:08.713543Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:08.713626Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4409", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:08.713708Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:08.713765Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:39.840801Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:50:39.842175Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:39.842280Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:39.842420Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:39.842521Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:39.842633Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2280 to=3000 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:39.842767Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0fc5cb64a2dc40350068fcd590e1f08198a3942bd8ad9fe552 model=gpt-5 max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:39.842935Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:39.843120Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:39.843202Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4409", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:39.843279Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T13:50:39.843364Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:10.256843Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:51:10.258776Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1868 output_len=0 content_len=1868", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:10.258896Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:10.258989Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=1868", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:10.259076Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=1868", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:10.259146Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:10.259988Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:10.260112Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=2320 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:51:10.260232Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:MAIN_TAIL_FILL_ACCEPT idx=2 tokens=2320 format=json", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:51:10.260329Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=partial kind=main label=main[1-2]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:51:10.260434Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:SCHEDULER_BLOCK main underflow=2 target_min=3 → continue_main", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:51:10.260545Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:SCHEDULER_BLOCK main underflow=2 target_min=3 → continue_main", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:51:10.260622Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:SCHEDULER_BLOCK main underflow=2 target_min=3 → continue_main", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:51:10.260798Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4525 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:51:11.176491Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:51:11.177228Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:11.177906Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:11.178836Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:11.179101Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:11.179170Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4599", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:11.179229Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:11.179285Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:43.433625Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:51:43.451559Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:43.451754Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:43.451977Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:43.452142Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:43.452257Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1915 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:43.452404Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ba8b1e5cfab36240068fcd5cf83f88193aedc8a16ce2a4675 model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:43.452586Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:43.452789Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:43.452875Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4599", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:43.452949Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T13:51:43.453024Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:52:15.384517Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:52:15.385461Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T13:52:15.385527Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:52:15.385613Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T13:52:15.385716Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T13:52:15.385797Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2280 to=3000 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:52:15.385889Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ba8b1e5cfab36240068fcd5efaa388193bf89eb5f4b3d2f45 model=gpt-5 max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T13:52:15.386000Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:52:15.386120Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:52:15.386172Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4599", "name": "llm_client"}
{"timestamp": "2025-10-25T13:52:15.386216Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T13:52:15.386258Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:06.172378Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:53:06.173165Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:06.173224Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:06.173293Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:06.173386Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:06.173476Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=3000 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:06.173590Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ba8b1e5cfab36240068fcd60f9d988193a37204047584c829 model=gpt-5 max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:06.173677Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:06.173773Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:06.173834Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4599", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:06.173882Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:06.173915Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:49.488636Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:53:49.632342Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1553 output_len=0 content_len=1553", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:49.632460Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:49.632575Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=1553", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:49.632693Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=1553", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:49.632763Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:49.632834Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:49.632953Z", "level": "INFO", "logger": "llm_client", "message": "RESP_INCOMPLETE_ACCEPT text len=1553", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:49.633719Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:49.633837Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=3556 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:53:49.634116Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4576 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:53:50.410027Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:53:50.410660Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:50.411134Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:50.412003Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:50.412129Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:50.412214Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4650", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:50.412285Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T13:53:50.412352Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T13:54:33.009013Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:54:33.010272Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T13:54:33.010383Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:54:33.010522Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T13:54:33.010629Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T13:54:33.010737Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1915 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:54:33.010833Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ba8b1e5cfab36240068fcd66ea36481938f788405686c4a99 model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T13:54:33.010943Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T13:54:33.011045Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:54:33.011118Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4650", "name": "llm_client"}
{"timestamp": "2025-10-25T13:54:33.011185Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T13:54:33.011262Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:17.145209Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:55:17.146666Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:17.146772Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:17.146918Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:17.147018Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:17.147123Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2280 to=3000 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:17.147217Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ba8b1e5cfab36240068fcd6993db8819386040608214d444e model=gpt-5 max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:17.147322Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:17.147422Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:17.147496Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4650", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:17.147568Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:17.147659Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:56.438813Z", "level": "INFO", "logger": "werkzeug", "message": "127.0.0.1 - - [25/Oct/2025 15:55:56] \"GET /api/jobs/488380b7c7ee418b94fe806d2d4d97b4/stream HTTP/1.1\" 200 -", "name": "werkzeug"}
{"timestamp": "2025-10-25T13:55:56.711187Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:55:56.712621Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=2216 output_len=0 content_len=2216", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:56.712689Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:56.712755Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=2216", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:56.712824Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=2216", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:56.712877Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:56.714162Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:56.714262Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=2162 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:55:56.714379Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "FALLBACK_ROUTE used=output_text kind=main label=main[3]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:55:56.714469Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=partial kind=main label=main[3]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:55:56.714630Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4530 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T13:55:57.027195Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T13:55:57.027744Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:57.028161Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:57.028785Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:57.028964Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:57.029021Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4604", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:57.029065Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T13:55:57.029108Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:59:34.412847Z", "level": "WARNING", "logger": "llm_client", "message": "responses retry attempt=1 sleep=1.00", "name": "llm_client"}
{"timestamp": "2025-10-25T13:59:35.414547Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T13:59:35.414955Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T13:59:35.415053Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4604", "name": "llm_client"}
{"timestamp": "2025-10-25T13:59:35.415132Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T13:59:35.415205Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:07.429879Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:00:07.432317Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:07.432573Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:07.432739Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:07.432829Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:07.432935Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1915 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:07.433048Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ff13abdf16b97420068fcd7c802c0819784286314bf9bb2ce model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:07.433189Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:07.433351Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:07.433416Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4604", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:07.433471Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:07.433526Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:46.809636Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:00:46.831130Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:46.831276Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:46.831436Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:46.831534Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:46.836533Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2280 to=3000 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:46.836788Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ff13abdf16b97420068fcd7e794cc8197b747c9d7992f68a8 model=gpt-5 max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:46.837004Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:46.837236Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:46.837328Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4604", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:46.839327Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:00:46.839445Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:01:34.162920Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:01:34.164412Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:01:34.164526Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:01:34.164720Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:01:34.164828Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:01:34.164939Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=3000 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:01:34.165081Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ff13abdf16b97420068fcd80ef6dc8197a861d5c1110aa814 model=gpt-5 max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:01:34.165269Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:01:34.165471Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:01:34.165539Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4604", "name": "llm_client"}
{"timestamp": "2025-10-25T14:01:34.165596Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:01:34.165653Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:02:29.559821Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:02:29.561867Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1651 output_len=0 content_len=1651", "name": "llm_client"}
{"timestamp": "2025-10-25T14:02:29.561973Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:02:29.562082Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=1651", "name": "llm_client"}
{"timestamp": "2025-10-25T14:02:29.562203Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=1651", "name": "llm_client"}
{"timestamp": "2025-10-25T14:02:29.562273Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:02:29.562345Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:02:29.562512Z", "level": "INFO", "logger": "llm_client", "message": "RESP_INCOMPLETE_ACCEPT text len=1651", "name": "llm_client"}
{"timestamp": "2025-10-25T14:02:29.563289Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:02:29.563447Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=3586 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:02:29.563855Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4581 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:02:30.068147Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:02:30.068774Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:02:30.069334Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:02:30.070270Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T14:02:30.070400Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:02:30.070486Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4655", "name": "llm_client"}
{"timestamp": "2025-10-25T14:02:30.070558Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:02:30.070628Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:30.072889Z", "level": "WARNING", "logger": "llm_client", "message": "responses retry attempt=1 sleep=1.00", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:31.073712Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:31.073810Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:31.073853Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4655", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:31.073888Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:31.073959Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:55.426158Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:03:55.427993Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1608 output_len=0 content_len=1608", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:55.428144Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:55.428274Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=1608", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:55.428346Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=1608", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:55.428388Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:55.428796Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:55.428865Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=1133 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:03:55.428974Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "FALLBACK_ROUTE used=output_text kind=main label=main[4]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:03:55.429044Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=partial kind=main label=main[4]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:03:55.429304Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4535 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:03:55.694033Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:03:55.694552Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:55.694925Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:55.695403Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:55.695539Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:55.695581Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4609", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:55.695616Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:03:55.695650Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:26.499208Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:04:26.499947Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:26.500006Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:26.500095Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:26.500145Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:26.500196Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1915 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:26.500306Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0a4adc4b1d7c96540068fcd8cc0c6481958cbc0c0cea253416 model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:26.500394Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:26.500490Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:26.500530Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4609", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:26.500564Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:26.500599Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:58.348136Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:04:58.349620Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:58.349728Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:58.349879Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:58.349982Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:58.350090Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2280 to=3000 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:58.350247Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0a4adc4b1d7c96540068fcd8ea9cf881959a62bbf3dee11b47 model=gpt-5 max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:58.350445Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:58.350604Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:58.350670Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4609", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:58.350728Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:04:58.350785Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:05:49.372668Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:05:49.374854Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:05:49.374948Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:05:49.375063Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:05:49.375147Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:05:49.375233Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=3000 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:05:49.375352Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0a4adc4b1d7c96540068fcd90a90188195b907b675371977f3 model=gpt-5 max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:05:49.375497Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:05:49.375659Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:05:49.375726Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4609", "name": "llm_client"}
{"timestamp": "2025-10-25T14:05:49.375783Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:05:49.375838Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:06:49.377712Z", "level": "WARNING", "logger": "llm_client", "message": "responses retry attempt=4 sleep=6.00", "name": "llm_client"}
{"timestamp": "2025-10-25T14:06:55.381743Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0a4adc4b1d7c96540068fcd90a90188195b907b675371977f3 model=gpt-5 max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:06:55.382118Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:06:55.382490Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:06:55.382610Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4609", "name": "llm_client"}
{"timestamp": "2025-10-25T14:06:55.382685Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:06:55.382757Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:07:55.453453Z", "level": "WARNING", "logger": "llm_client", "message": "responses retry attempt=5 sleep=8.00", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:03.456008Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0a4adc4b1d7c96540068fcd90a90188195b907b675371977f3 model=gpt-5 max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:03.456212Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:03.456517Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:03.456584Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4609", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:03.456635Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:03.456682Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:58.905932Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:08:58.908093Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=2176 output_len=0 content_len=2176", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:58.908233Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:58.908511Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=2176", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:58.908697Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=2176", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:58.908840Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:58.909010Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:58.909179Z", "level": "INFO", "logger": "llm_client", "message": "RESP_INCOMPLETE_ACCEPT text len=2176", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:58.910909Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:58.911024Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=3579 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:08:58.911447Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4586 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:08:59.842764Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:08:59.843649Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:59.844396Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:59.845434Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:59.845712Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:59.845799Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4660", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:59.845865Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:08:59.845968Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:31.984525Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:09:31.986738Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1418 output_len=0 content_len=1418", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:31.986858Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:31.986951Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=1418", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:31.987038Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=1418", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:31.987109Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:31.988080Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:31.988199Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=1013 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:09:31.988344Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "FALLBACK_ROUTE used=output_text kind=main label=main[5]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:09:31.988464Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=partial kind=main label=main[5]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:09:31.988695Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4597 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:09:32.577532Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:09:32.578113Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:32.578792Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:32.579737Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:32.580020Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:32.580107Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4671", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:32.580202Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:32.580259Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:56.522580Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:09:56.524517Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1067 output_len=0 content_len=1067", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:56.524602Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:56.524687Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=1067", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:56.524773Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=1067", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:56.524842Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:56.525881Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:56.525995Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=1731 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:09:56.526250Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=faq label=faq[1-3]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:09:56.526483Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4597 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:09:56.847100Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:09:56.847722Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:56.848429Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:56.849399Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:56.849684Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:56.849755Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4671", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:56.849814Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:09:56.849871Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:10:23.401159Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:10:23.402382Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:10:23.402458Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:10:23.402550Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:10:23.402622Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:10:23.402692Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1915 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:10:23.402818Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_02200c987e0158df0068fcda34f75881999404c37eb37e0d61 model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:10:23.403056Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:10:23.403224Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:10:23.403286Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4671", "name": "llm_client"}
{"timestamp": "2025-10-25T14:10:23.403344Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:10:23.403400Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:11:01.675216Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:11:01.676149Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:11:01.676217Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:11:01.676309Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:11:01.676374Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:11:01.676443Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2280 to=3000 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:11:01.676533Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_02200c987e0158df0068fcda4f875081999c4d981c2c482d2a model=gpt-5 max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:11:01.676646Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:11:01.676775Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:11:01.676827Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4671", "name": "llm_client"}
{"timestamp": "2025-10-25T14:11:01.676871Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:11:01.676915Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:00.948868Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:12:00.950436Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=694 output_len=0 content_len=694", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:00.950541Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:00.950646Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=694", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:00.950753Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=694", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:00.950839Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:00.952024Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:00.952138Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=1881 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:12:00.952292Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=faq label=faq[4-5]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:12:00.952487Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4314 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:12:01.726112Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:12:01.726860Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:01.727323Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:01.728018Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:01.728177Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:01.728254Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4388", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:01.728313Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:01.728371Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:44.040830Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:12:44.042050Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:44.042155Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:44.042288Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:44.042386Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:44.042487Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1915 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:44.042606Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ff6fd8fe353cf990068fcdab213b08193bdec593b29eed24a model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:44.042747Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:44.042896Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:44.042958Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4388", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:44.043013Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:12:44.043067Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:14.675997Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:13:14.677689Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1033 output_len=0 content_len=1033", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:14.677797Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:14.677905Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=1033", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:14.678016Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=1033", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:14.678103Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:14.679007Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:14.679119Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=1704 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:13:14.679258Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=conclusion label=conclusion", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:13:14.679696Z", "level": "INFO", "logger": "skeleton_utils", "message": "LOG:SKELETON_NORMALIZED keys=intro,main[],faq[],conclusion", "name": "skeleton_utils"}
{"timestamp": "2025-10-25T14:13:14.680628Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "SKELETON_OK route=responses", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:13:14.686903Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "KEYWORDS_COVERAGE required=100% overall=100% missing_required=- missing_preferred=-", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:13:14.686974Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "KEYWORDS_OK coverage_required=100.00% coverage_overall=100.00%", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:13:14.687964Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "FAQ_OK entries=4. Как посчитать свою долговую нагрузку перед подачей заявки?,№2. Что делать, если отказали в Кредит из‑за высокой нагрузки?,№3. Как быстро сократить платежи, чтобы оставались Деньги на обязательные траты?,5. Что сделать в первую очередь, чтобы снизить платежи по действующим займам?,№1. Как рассчитать показатель «Долговая нагрузка» и понять, в норме ли он?", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:13:14.721491Z", "level": "WARNING", "logger": "content_factory.pipeline", "message": "TRIM_LEN_RELAXED length=11001 range=3500-6000 soft_range=3430-6120", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:13:15.595927Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:13:15.596453Z", "level": "INFO", "logger": "orchestrate", "message": "responses input_len=25", "name": "orchestrate"}
{"timestamp": "2025-10-25T14:13:16.157924Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 400 Bad Request\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:13:16.158386Z", "level": "INFO", "logger": "orchestrate", "message": "responses input_len=25", "name": "orchestrate"}
{"timestamp": "2025-10-25T14:13:17.566643Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:13:17.572261Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "SKELETON_ESTIMATE predicted=1532 start_max=1915 cap=3600 → resolved max_output_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:13:17.572622Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4478 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:13:18.086893Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:13:18.087439Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:18.088063Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:18.088975Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:18.089230Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:18.089318Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4552", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:18.089379Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:18.089436Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:41.403227Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:13:41.404724Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=512 output_len=0 content_len=512", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:41.404829Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:41.404947Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=512", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:41.405056Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=512", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:41.405142Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=completed|-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:41.405821Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:41.405939Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=1555 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:13:41.406133Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=complete kind=intro label=intro", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:13:41.406341Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4456 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:13:41.922977Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:13:41.923541Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:41.924211Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:41.925141Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:41.925424Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:41.925510Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4530", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:41.925611Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:13:41.925668Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:12.848128Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:14:12.849470Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:12.849575Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:12.849710Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:12.849810Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:12.849913Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1915 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:12.850048Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_02ecde3d7300a08c0068fcdb161af4819891ac4c4e77902eac model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:12.850220Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:12.850420Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:12.850522Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4530", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:12.850580Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:12.850638Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:46.742737Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:14:46.744057Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:46.744163Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:46.744310Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:46.744412Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:46.744518Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2280 to=3000 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:46.744656Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_02ecde3d7300a08c0068fcdb34f1b0819893ddecba845dcbb6 model=gpt-5 max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:46.744830Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:46.745028Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:46.745128Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4530", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:46.745187Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:14:46.745246Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:15:27.599971Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:15:27.600818Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:15:27.600883Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:15:27.600967Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:15:27.601028Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:15:27.601097Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=3000 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:15:27.601187Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_02ecde3d7300a08c0068fcdb56ece08198b89a146890fb4181 model=gpt-5 max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:15:27.601343Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:15:27.601471Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:15:27.601520Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4530", "name": "llm_client"}
{"timestamp": "2025-10-25T14:15:27.601579Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:15:27.601624Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:16:27.603353Z", "level": "WARNING", "logger": "llm_client", "message": "responses retry attempt=4 sleep=6.00", "name": "llm_client"}
{"timestamp": "2025-10-25T14:16:33.604309Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_02ecde3d7300a08c0068fcdb56ece08198b89a146890fb4181 model=gpt-5 max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:16:33.604583Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:16:33.604766Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:16:33.604808Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4530", "name": "llm_client"}
{"timestamp": "2025-10-25T14:16:33.604872Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:16:33.604951Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:17:27.512251Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:17:27.557339Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=3166 output_len=0 content_len=3166", "name": "llm_client"}
{"timestamp": "2025-10-25T14:17:27.557462Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:17:27.557579Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=3166", "name": "llm_client"}
{"timestamp": "2025-10-25T14:17:27.557692Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=3166", "name": "llm_client"}
{"timestamp": "2025-10-25T14:17:27.557781Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:17:27.557878Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:17:27.558039Z", "level": "INFO", "logger": "llm_client", "message": "RESP_INCOMPLETE_ACCEPT text len=3166", "name": "llm_client"}
{"timestamp": "2025-10-25T14:17:27.558927Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:17:27.559039Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=3566 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:17:27.559411Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4495 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:17:28.023866Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:17:28.024388Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:17:28.024851Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:17:28.025739Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T14:17:28.025872Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:17:28.025959Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4569", "name": "llm_client"}
{"timestamp": "2025-10-25T14:17:28.026031Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:17:28.026101Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:11.166664Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:18:11.168278Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1128 output_len=0 content_len=1128", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:11.168388Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:11.168499Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=1128", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:11.168609Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=1128", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:11.168696Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:11.168787Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:11.168877Z", "level": "INFO", "logger": "llm_client", "message": "RESP_INCOMPLETE_ACCEPT text len=1128", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:11.169686Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:11.169798Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=1865 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:18:11.169910Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "FALLBACK_ROUTE used=output_text kind=main label=main[1-2]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:18:11.170014Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:TAIL_FILL_FORCED reason=missing_content kind=main items=1", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:18:11.170086Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:MAIN_TAIL_FILL start missing=1", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:18:11.170228Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4335 attempt=1 max_tokens=600", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:18:11.495789Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:18:11.496319Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=600 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:11.496939Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=600 (requested=600, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:11.497826Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:11.498083Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:11.498196Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4409", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:11.498257Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:11.498315Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:21.579635Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:18:21.580952Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:21.581058Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:21.581206Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:21.581308Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:21.581412Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=600 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:21.581546Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0841aaf597aff60f0068fcdc2422b08198969fa73274219cd7 model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:21.581710Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:21.581896Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:21.581998Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4409", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:21.582056Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:21.582113Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:49.841908Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:18:49.843683Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1080 output_len=0 content_len=1080", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:49.843791Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:49.843909Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=1080", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:49.844021Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=1080", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:49.844110Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:49.844203Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:49.844338Z", "level": "INFO", "logger": "llm_client", "message": "RESP_INCOMPLETE_ACCEPT text len=1080", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:49.845470Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:49.845589Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=2259 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:18:49.845755Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:MAIN_TAIL_FILL_ACCEPT idx=2 tokens=2259 format=stub", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:18:49.845854Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=partial kind=main label=main[1-2]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:18:49.845954Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:SCHEDULER_BLOCK main underflow=2 target_min=3 → continue_main", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:18:49.846036Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:SCHEDULER_BLOCK main underflow=2 target_min=3 → continue_main", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:18:49.846108Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:SCHEDULER_BLOCK main underflow=2 target_min=3 → continue_main", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:18:49.846267Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4528 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:18:50.324056Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:18:50.324638Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:50.325292Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:50.326222Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:50.326500Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:50.326665Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4602", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:50.326762Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:18:50.326825Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:16.773444Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:19:16.774894Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:16.775001Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:16.775144Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:16.775245Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:16.775348Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1915 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:16.775488Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ef1e67b9a9b72df0068fcdc4a7dbc8199b29625c70c95a157 model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:16.775662Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:16.775877Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:16.775945Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4602", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:16.776004Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:16.776060Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:46.162650Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:19:46.164065Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:46.164172Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:46.164321Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:46.164424Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:46.164534Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2280 to=3000 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:46.164673Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ef1e67b9a9b72df0068fcdc64e99081999e598c918e0cedb2 model=gpt-5 max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:46.164851Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:46.165064Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:46.165132Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4602", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:46.165189Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:19:46.165245Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:20:23.206840Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:20:23.207779Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:20:23.207844Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:20:23.207926Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:20:23.207985Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:20:23.208096Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=3000 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:20:23.208199Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ef1e67b9a9b72df0068fcdc8243408199861e08914cf79c4c model=gpt-5 max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:20:23.208311Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:20:23.208432Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:20:23.208480Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4602", "name": "llm_client"}
{"timestamp": "2025-10-25T14:20:23.208522Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:20:23.208561Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:07.264223Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:21:07.279055Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:07.279266Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:07.279439Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:07.279545Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:07.279658Z", "level": "WARNING", "logger": "llm_client", "message": "LLM_WARN cap_reached limit=3600 output_len=0 content_len=0 status=incomplete reason=max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:07.280442Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:07.280582Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=3584 status=incomplete", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:21:07.280670Z", "level": "WARNING", "logger": "content_factory.pipeline", "message": "LLM_INCOMPLETE_RETURN step=skeleton status=incomplete reason=max_output_tokens_final", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:21:07.280895Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4528 attempt=1 max_tokens=930", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:21:07.673339Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:21:07.673850Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=930 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:07.674511Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=930 (requested=930, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:07.675343Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:07.675569Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:07.675640Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4602", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:07.675701Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=930", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:07.675758Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:19.449939Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:21:19.451447Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:19.451556Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:19.451706Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:19.451808Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=930", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:19.451914Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=930 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:19.452054Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ef1e67b9a9b72df0068fcdcd3cc088199ba2341875c5566b5 model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:19.452230Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:19.452432Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:19.452526Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4602", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:19.452583Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:19.452638Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:48.121896Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:21:48.123267Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:48.123374Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:48.123514Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:48.123615Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:48.123719Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=2280 to=3000 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:48.123861Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ef1e67b9a9b72df0068fcdcdf95348199b9c3e4b39159f66a model=gpt-5 max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:48.124034Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:48.124233Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:48.124315Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4602", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:48.124413Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:21:48.124467Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:22:38.708249Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:22:38.709720Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:22:38.709827Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:22:38.709975Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:22:38.710079Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3000", "name": "llm_client"}
{"timestamp": "2025-10-25T14:22:38.710188Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=3000 to=3600 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:22:38.710335Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ef1e67b9a9b72df0068fcdcfc42a48199adb9bd09d3538428 model=gpt-5 max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:22:38.710514Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:22:38.710719Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:22:38.710813Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4602", "name": "llm_client"}
{"timestamp": "2025-10-25T14:22:38.710873Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:22:38.710928Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:23:38.622034Z", "level": "WARNING", "logger": "llm_client", "message": "responses retry attempt=4 sleep=6.00", "name": "llm_client"}
{"timestamp": "2025-10-25T14:23:44.622489Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ef1e67b9a9b72df0068fcdcfc42a48199adb9bd09d3538428 model=gpt-5 max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:23:44.622987Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:23:44.623386Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:23:44.623484Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4602", "name": "llm_client"}
{"timestamp": "2025-10-25T14:23:44.623559Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:23:44.623634Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:29.414430Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:24:29.416769Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1657 output_len=0 content_len=1657", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:29.416883Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:29.416968Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=1657", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:29.417055Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=1657", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:29.417124Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:29.417196Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:29.417311Z", "level": "INFO", "logger": "llm_client", "message": "RESP_INCOMPLETE_ACCEPT text len=1657", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:29.418365Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:29.418466Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=3549 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:24:29.418710Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4571 attempt=1 max_tokens=930", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:24:30.028892Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:24:30.029518Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=930 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:30.030026Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=930 (requested=930, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:30.030882Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:30.031009Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:30.031093Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4645", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:30.031164Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=930", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:30.031295Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:55.117527Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:24:55.118843Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:55.118946Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:55.119080Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:55.119176Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=930", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:55.119277Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=930 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:55.119374Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ef1e67b9a9b72df0068fcdd9e390c8199bbf9467998e83af0 model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:55.119480Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:55.119578Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:55.119651Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4645", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:55.119720Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:24:55.119786Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=text name=- has_schema=False", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:34.234187Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:25:34.235630Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=759 output_len=0 content_len=759", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:34.235737Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:34.235851Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=759", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:34.235963Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=759", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:34.236050Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:34.236139Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:34.236229Z", "level": "INFO", "logger": "llm_client", "message": "RESP_INCOMPLETE_ACCEPT text len=759", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:34.236848Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:34.236966Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=2262 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:25:34.237073Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "FALLBACK_ROUTE used=output_text kind=main label=main[3-4]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:25:34.237183Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:TAIL_FILL_FORCED reason=missing_content kind=main items=3", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:25:34.237254Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:MAIN_TAIL_FILL start missing=1", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:25:34.237391Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4362 attempt=1 max_tokens=600", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:25:35.053836Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:25:35.054379Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=600 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:35.055005Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=600 (requested=600, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:35.055912Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:35.056167Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:35.056263Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4436", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:35.056323Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:35.056380Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:44.678633Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:25:44.680074Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:44.680179Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:44.680324Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:44.680426Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:44.680528Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=600 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:44.680661Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0d15f9320337cca90068fcdddf6df88199a8687c1cd00e66f5 model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:44.680826Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:44.681018Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:44.681107Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4436", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:44.681166Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:25:44.681221Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:12.224564Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:26:12.227030Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=content_text len=1077 output_len=0 content_len=1077", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:12.227114Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=output segments=1 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:12.227199Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE_OK schema=responses.none len=1077", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:12.227294Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTENT_STARTED len=1077", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:12.227363Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:12.227437Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:12.227546Z", "level": "INFO", "logger": "llm_client", "message": "RESP_INCOMPLETE_ACCEPT text len=1077", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:12.228438Z", "level": "INFO", "logger": "llm_client", "message": "completion schema category=responses.none (schema=responses.none, route=responses, attempt=primary)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:12.228557Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_RESPONSE step=skeleton tokens_used=2240 status=completed", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:26:12.228720Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:MAIN_TAIL_FILL_ACCEPT idx=4 tokens=2240 format=stub", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:26:12.228817Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "BATCH_ACCEPT state=partial kind=main label=main[3-4]", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:26:12.229001Z", "level": "INFO", "logger": "content_factory.pipeline", "message": "LOG:LLM_REQUEST step=skeleton model=gpt-5 prompt_len=4578 attempt=1 max_tokens=1915", "name": "content_factory.pipeline"}
{"timestamp": "2025-10-25T14:26:12.838831Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET https://api.openai.com/v1/models/gpt-5 \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:26:12.839364Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ATTEMPT label=primary max_tokens=1915 fallback=-", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:12.840052Z", "level": "INFO", "logger": "llm_client", "message": "resolved max_output_tokens=1915 (requested=1915, cap=3600)", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:12.841009Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:12.841301Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:12.841372Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4652", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:12.841432Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:12.841489Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:37.439609Z", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"", "name": "httpx"}
{"timestamp": "2025-10-25T14:26:37.440945Z", "level": "INFO", "logger": "llm_client", "message": "RESP_PARSE=none len=0 output_len=0 content_len=0", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:37.441052Z", "level": "INFO", "logger": "llm_client", "message": "responses parse resp_keys=['background', 'billing', 'created_at', 'error', 'id', 'incomplete_details', 'instructions', 'max_output_tokens', 'max_tool_calls', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'previous_response_id', 'prompt_cache_key', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'store', 'text', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'truncation', 'usage', 'user'] root=None segments=0 schema=responses.none", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:37.441197Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:37.441298Z", "level": "INFO", "logger": "llm_client", "message": "RESP_STATUS=incomplete|max_output_tokens=1915", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:37.441402Z", "level": "INFO", "logger": "llm_client", "message": "RESP_ESCALATE_TOKENS reason=max_output_tokens from=1915 to=2280 cap=3600", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:37.441539Z", "level": "INFO", "logger": "llm_client", "message": "RESP_CONTINUE previous_response_id=resp_0ea322f839dea3c20068fcde0508288195b1a527f6c16ecbde model=gpt-5 max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:37.441719Z", "level": "INFO", "logger": "llm_client", "message": "LOG:RESP_PAYLOAD_FORMAT type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:37.441924Z", "level": "INFO", "logger": "llm_client", "message": "responses payload_keys=['input', 'max_output_tokens', 'model', 'previous_response_id', 'text']", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:37.442021Z", "level": "INFO", "logger": "llm_client", "message": "responses input_len=4652", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:37.442077Z", "level": "INFO", "logger": "llm_client", "message": "responses max_output_tokens=2280", "name": "llm_client"}
{"timestamp": "2025-10-25T14:26:37.442134Z", "level": "INFO", "logger": "llm_client", "message": "responses text_format type=json_schema name=seo_article_skeleton has_schema=True", "name": "llm_client"}
{
