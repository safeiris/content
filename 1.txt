diff --git a/orchestrate.py b/orchestrate.py
index e83dde4b3f48800d9d2f93b06d089a63107a0c76..26d88f5d7447154f60c7233603ca4bed33d5b47b 100644
--- a/orchestrate.py
+++ b/orchestrate.py
@@ -866,53 +866,58 @@ def _run_health_ping() -> Dict[str, object]:
         LOGGER.warning("health_ping http_error exception=%s endpoint=%s", reason, endpoint)
         _log_health(latency_ms)
         return {
             "ok": False,
             "message": f"Responses недоступен: {reason}",
             "route": route,
             "fallback_used": fallback_used,
             "latency_ms": latency_ms,
         }
 
     status = str(data.get("status", "")).strip().lower()
     incomplete_reason = ""
     incomplete_details = data.get("incomplete_details")
     if isinstance(incomplete_details, dict):
         reason_value = incomplete_details.get("reason")
         if isinstance(reason_value, str):
             incomplete_reason = reason_value.strip().lower()
 
     got_output = False
     output_text = data.get("output_text")
     if isinstance(output_text, str) and output_text.strip():
         got_output = True
     elif isinstance(data.get("output"), list) or isinstance(data.get("outputs"), list):
         got_output = True
 
+    ok = False
     if status == "completed":
         message = f"Responses OK (gpt-5, {max_tokens} токенов)"
         ok = True
+    elif status == "incomplete" and incomplete_reason in {"max_output_tokens", "max_tokens"}:
+        suffix = "с обрезкой по max_output_tokens"
+        message = f"Responses OK (gpt-5, {max_tokens} токенов, {suffix})"
+        ok = True
     else:
         if not status:
             reason = "неизвестный статус"
         else:
             reason = status
             if incomplete_reason:
                 reason = f"{reason} ({incomplete_reason})"
         LOGGER.warning("health_ping bad_status status=%s endpoint=%s", status or "", endpoint)
         _log_health(latency_ms)
         return {
             "ok": False,
             "message": f"Responses недоступен: статус {reason}",
             "route": route,
             "fallback_used": fallback_used,
             "latency_ms": latency_ms,
             "status": status or "",
         }
 
     result: Dict[str, object] = {
         "ok": ok,
         "message": message,
         "route": route,
         "fallback_used": fallback_used,
         "latency_ms": latency_ms,
         "tokens": max_tokens,
diff --git a/tests/test_health.py b/tests/test_health.py
index 2f12ea280c1b974f3724c27da378f85138be566f..cfa3b284d482838fff7aa0f42a4f1a143a3fed78 100644
--- a/tests/test_health.py
+++ b/tests/test_health.py
@@ -69,50 +69,73 @@ def test_health_ping_success(monkeypatch):
 
     monkeypatch.setattr(orchestrate.httpx, "Client", _client_factory)
 
     result = orchestrate._run_health_ping()
 
     assert result["ok"] is True
     assert result["route"] == LLM_ROUTE
     assert result["fallback_used"] is LLM_ALLOW_FALLBACK
     expected_label = f"Responses OK (gpt-5, {orchestrate.HEALTH_INITIAL_MAX_TOKENS} токенов)"
     assert expected_label in result["message"]
 
     assert isinstance(client.timeout, httpx.Timeout)
     assert client.timeout.read == 40.0
     assert client.timeout.connect == 10.0
     assert client.timeout.write == 10.0
     assert client.timeout.pool == 10.0
 
     assert len(client.requests) == 1
     request_payload = client.requests[0]["json"]
     assert request_payload["max_output_tokens"] == orchestrate.HEALTH_INITIAL_MAX_TOKENS
     assert request_payload["input"] == orchestrate.HEALTH_PROMPT
     assert request_payload["text"]["format"]["type"] == "text"
     assert "temperature" not in request_payload
 
 
+def test_health_ping_incomplete_max_tokens(monkeypatch):
+    payload = {
+        "status": "incomplete",
+        "output_text": "partial",
+        "incomplete_details": {"reason": "max_output_tokens"},
+    }
+    responses = [_response(200, payload)]
+    client = DummyHealthClient(responses)
+
+    def _client_factory(timeout=None):
+        client.timeout = timeout
+        return client
+
+    monkeypatch.setattr(orchestrate.httpx, "Client", _client_factory)
+
+    result = orchestrate._run_health_ping()
+
+    assert result["ok"] is True
+    assert result["status"] == "incomplete"
+    assert result["incomplete_reason"] == "max_output_tokens"
+    assert "с обрезкой по max_output_tokens" in result["message"]
+
+
 def test_health_ping_5xx_failure(monkeypatch):
     responses = [_response(502, None, text="Bad gateway")]
     client = DummyHealthClient(responses)
     def _client_factory(timeout=None):
         client.timeout = timeout
         return client
 
     monkeypatch.setattr(orchestrate.httpx, "Client", _client_factory)
 
     result = orchestrate._run_health_ping()
 
     assert result["ok"] is False
     assert "HTTP 502" in result["message"]
     assert len(client.requests) == 1
 
 
 def test_health_ping_400_invalid_max_tokens(monkeypatch):
     payload = {
         "error": {
             "message": "max_output_tokens too small; expected >= 64",
         }
     }
     responses = [_response(400, payload)]
     client = DummyHealthClient(responses)
 

