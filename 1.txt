diff --git a/deterministic_pipeline.py b/deterministic_pipeline.py
index 7e7d45981074ab672302c3be99a3e738b2481ebd..90b5006207621c856339a0abce269a7c30796634 100644
--- a/deterministic_pipeline.py
+++ b/deterministic_pipeline.py
@@ -776,63 +776,72 @@ class DeterministicPipeline:
         format_block = {
             "type": "json_schema",
             "name": name_map.get(batch.kind, "seo_article_skeleton_batch"),
             "schema": schema,
             "strict": True,
         }
         return self._prepare_format_block(format_block, batch=batch)
 
     def _prepare_format_block(
         self,
         format_block: Dict[str, object],
         *,
         batch: SkeletonBatchPlan,
     ) -> Dict[str, object]:
         fmt_type = str(format_block.get("type") or "").lower()
         if fmt_type == "json_schema":
             schema = format_block.get("schema")
             if not isinstance(schema, dict):
                 raise PipelineStepError(
                     PipelineStep.SKELETON,
                     "Некорректная схема ответа для батча скелета.",
                 )
             self._enforce_schema_defaults(schema)
         format_name = str(format_block.get("name") or "")
         if (
-            batch.kind != SkeletonBatchKind.INTRO
+            batch.kind in (
+                SkeletonBatchKind.MAIN,
+                SkeletonBatchKind.FAQ,
+                SkeletonBatchKind.CONCLUSION,
+            )
             and format_name.strip() == "seo_article_skeleton"
         ):
-            LOGGER.error(
-                "FORMAT_GUARD triggered kind=%s label=%s name=%s",
+            replacement_map = {
+                SkeletonBatchKind.MAIN: "seo_article_main_batch",
+                SkeletonBatchKind.FAQ: "seo_article_faq_batch",
+                SkeletonBatchKind.CONCLUSION: "seo_article_conclusion_batch",
+            }
+            replacement = replacement_map.get(batch.kind, "seo_article_skeleton_batch")
+            LOGGER.warning(
+                "LOG:BAT_FMT_FIXUP kind=%s label=%s from=%s to=%s",
                 batch.kind.value,
                 batch.label or self._format_batch_label(batch.kind, batch.indices),
                 format_name,
+                replacement,
             )
-            raise PipelineStepError(
-                PipelineStep.SKELETON,
-                "Недопустимое имя формата для батча скелета.",
-            )
+            format_block = dict(format_block)
+            format_block["name"] = replacement
         return format_block
 
     def _enforce_schema_defaults(self, schema: Dict[str, object], path: str = "$") -> None:
         if not isinstance(schema, dict):
             raise PipelineStepError(
                 PipelineStep.SKELETON,
                 f"Невалидная структура схемы по пути {path}.",
             )
         node_type = str(schema.get("type") or "")
         if node_type == "object":
             properties = schema.get("properties")
             if isinstance(properties, dict):
                 if "additionalProperties" not in schema:
                     schema["additionalProperties"] = False
                 required = schema.get("required")
                 if isinstance(required, list):
                     missing = [
                         str(field)
                         for field in required
                         if field not in properties
                     ]
                     if missing:
                         missing_fields = ", ".join(sorted(missing))
                         raise PipelineStepError(
                             PipelineStep.SKELETON,
@@ -1416,50 +1425,58 @@ class DeterministicPipeline:
                     "Ответ будет расширен после полного завершения генерации скелета."
                 )
                 faq_entries.append({"q": question, "a": answer})
             return {"faq": faq_entries}
         if batch.kind == SkeletonBatchKind.CONCLUSION:
             return {
                 "conclusion": (
                     "Вывод будет дополнен после завершения основной генерации текста."
                 )
             }
         return None
 
     def _tail_fill_batch(
         self,
         batch: SkeletonBatchPlan,
         *,
         outline: SkeletonOutline,
         assembly: SkeletonAssembly,
         estimate: SkeletonVolumeEstimate,
         missing_items: Sequence[int],
         metadata: Dict[str, object],
     ) -> None:
         pending = [int(item) for item in missing_items if isinstance(item, int)]
         if not pending:
             return
+        if batch.kind == SkeletonBatchKind.MAIN:
+            self._tail_fill_main_sections(
+                indices=pending,
+                outline=outline,
+                assembly=assembly,
+                estimate=estimate,
+            )
+            return
         previous_id = self._metadata_response_id(metadata)
         if not previous_id:
             return
         if batch.kind in (SkeletonBatchKind.MAIN, SkeletonBatchKind.FAQ):
             groups = [[index] for index in pending]
         else:
             groups = [list(pending)]
 
         for group in groups:
             if not group:
                 continue
             tail_plan = SkeletonBatchPlan(
                 kind=batch.kind,
                 indices=list(group),
                 label=batch.label + "#tail",
                 tail_fill=True,
             )
             messages, format_block = self._build_batch_messages(
                 tail_plan,
                 outline=outline,
                 assembly=assembly,
                 target_indices=list(group),
                 tail_fill=True,
             )
             budget = self._batch_token_budget(batch, estimate, len(group))
@@ -1524,69 +1541,341 @@ class DeterministicPipeline:
                         headers = headers + outline.main_headings[len(headers) :]
                     assembly.apply_intro(
                         normalized.get("intro"),
                         headers,
                         normalized.get("conclusion_heading"),
                     )
                 if missing_fields:
                     raise PipelineStepError(
                         PipelineStep.SKELETON,
                         "Не удалось завершить вводный блок скелета.",
                     )
             else:
                 conclusion_text, missing = self._normalize_conclusion_batch(payload)
                 if conclusion_text:
                     assembly.apply_conclusion(conclusion_text)
                 if missing:
                     raise PipelineStepError(
                         PipelineStep.SKELETON,
                         "Не удалось завершить вывод скелета.",
                     )
             self._apply_inline_faq(payload, assembly)
             for key, value in tail_metadata.items():
                 if value:
                     metadata[key] = value
 
+    def _tail_fill_main_sections(
+        self,
+        *,
+        indices: Sequence[int],
+        outline: SkeletonOutline,
+        assembly: SkeletonAssembly,
+        estimate: SkeletonVolumeEstimate,
+    ) -> None:
+        targets = [idx for idx in indices if 0 <= idx < len(outline.main_headings)]
+        if not targets:
+            return
+        LOGGER.info("LOG:MAIN_TAIL_FILL start missing=%d", len(targets))
+        for index in targets:
+            heading = (
+                outline.main_headings[index]
+                if index < len(outline.main_headings)
+                else f"Блок {index + 1}"
+            )
+            messages, format_block = self._build_main_tail_fill_messages(
+                outline=outline,
+                assembly=assembly,
+                target_index=index,
+                heading=heading,
+            )
+            budget = max(600, min(estimate.per_main_tokens + 160, 900))
+            result = self._call_llm(
+                step=PipelineStep.SKELETON,
+                messages=messages,
+                max_tokens=budget,
+                responses_format=format_block,
+            )
+            payload = self._extract_response_json(result.text)
+            format_used = "json"
+            resolved_heading = heading
+            body_text = ""
+            if isinstance(payload, dict):
+                section_payload: Optional[Dict[str, object]] = None
+                section_block = payload.get("section")
+                if isinstance(section_block, dict):
+                    section_payload = section_block
+                else:
+                    sections = payload.get("sections")
+                    if isinstance(sections, list) and sections:
+                        candidate = sections[0]
+                        if isinstance(candidate, dict):
+                            section_payload = candidate
+                if section_payload is not None:
+                    heading_candidate = str(
+                        section_payload.get("title")
+                        or section_payload.get("heading")
+                        or ""
+                    ).strip()
+                    body_candidate = str(
+                        section_payload.get("body")
+                        or section_payload.get("text")
+                        or ""
+                    ).strip()
+                    if heading_candidate:
+                        resolved_heading = heading_candidate
+                    if body_candidate:
+                        body_text = body_candidate
+            if not body_text:
+                fallback = self._parse_fallback_main(
+                    result.text,
+                    target_index=index,
+                    outline=outline,
+                )
+                if fallback and isinstance(fallback, dict):
+                    sections = fallback.get("sections")
+                    if isinstance(sections, list) and sections:
+                        candidate = sections[0]
+                        if isinstance(candidate, dict):
+                            heading_candidate = str(
+                                candidate.get("title")
+                                or candidate.get("heading")
+                                or ""
+                            ).strip()
+                            body_candidate = str(
+                                candidate.get("body")
+                                or candidate.get("text")
+                                or ""
+                            ).strip()
+                            if heading_candidate:
+                                resolved_heading = heading_candidate
+                            if body_candidate:
+                                body_text = body_candidate
+                                format_used = "text"
+            if not body_text:
+                body_text = (
+                    "Этот раздел будет дополнен подробными рекомендациями по теме."
+                    " Пока используем короткий абзац-заглушку."
+                )
+                format_used = "stub"
+            assembly.apply_main(index, body_text, heading=resolved_heading)
+            usage = self._extract_usage(result)
+            tokens_repr = "-" if usage is None else f"{int(round(usage))}"
+            LOGGER.info(
+                "LOG:MAIN_TAIL_FILL_ACCEPT idx=%d tokens=%s format=%s",
+                index + 1,
+                tokens_repr,
+                format_used,
+            )
+
+    def _build_main_tail_fill_messages(
+        self,
+        *,
+        outline: SkeletonOutline,
+        assembly: SkeletonAssembly,
+        target_index: int,
+        heading: str,
+    ) -> Tuple[List[Dict[str, object]], Dict[str, object]]:
+        messages = [dict(message) for message in self.messages]
+        existing_sections: List[str] = []
+        for idx, title in enumerate(outline.main_headings):
+            if idx == target_index:
+                continue
+            body = assembly.main_sections[idx] if idx < len(assembly.main_sections) else None
+            if body and str(body).strip():
+                existing_sections.append(f"{idx + 1}. {title}")
+        lines = [
+            "Ты дополняешь основной раздел SEO-статьи.",
+            f"Тема: {self.topic}.",
+            "Нужно подготовить одну новую секцию основной части, без повторов уже готовых блоков.",
+            f"Целевой заголовок: {heading}.",
+        ]
+        if existing_sections:
+            lines.append("Уже готовые разделы: " + "; ".join(existing_sections) + ".")
+        lines.extend(
+            [
+                "Секция должна содержать 3–4 абзаца по 3–4 предложения, с цифрами, рисками и действиями.",
+                "Сконцентрируйся на практических советах и логичной структуре.",
+                "Верни JSON {\"section\": {\"title\": str, \"body\": str}} без пояснений.",
+                "Строго одна новая секция основной части, без повторов.",
+            ]
+        )
+        if self.normalized_keywords:
+            lines.append(
+                "По возможности используй ключевые слова: "
+                + ", ".join(self.normalized_keywords)
+                + "."
+            )
+        user_payload = textwrap.dedent("\n".join(lines)).strip()
+        messages.append({"role": "user", "content": user_payload})
+        schema = {
+            "type": "object",
+            "properties": {
+                "section": {
+                    "type": "object",
+                    "properties": {
+                        "title": {"type": "string"},
+                        "body": {"type": "string"},
+                    },
+                    "required": ["title", "body"],
+                    "additionalProperties": False,
+                }
+            },
+            "required": ["section"],
+            "additionalProperties": False,
+        }
+        format_block = {
+            "type": "json_schema",
+            "name": "seo_article_main_batch_one",
+            "schema": schema,
+            "strict": True,
+        }
+        plan = SkeletonBatchPlan(
+            kind=SkeletonBatchKind.MAIN,
+            indices=[target_index],
+            label=f"main[{target_index + 1}]",
+            tail_fill=True,
+        )
+        return messages, self._prepare_format_block(format_block, batch=plan)
+
+    def _append_main_heading_to_base_outline(self, heading: str) -> None:
+        normalized = str(heading or "").strip()
+        if not normalized:
+            return
+        if normalized in self.base_outline:
+            return
+        faq_markers = {"faq", "f.a.q.", "вопросы и ответы"}
+        insert_pos = len(self.base_outline)
+        for idx in range(1, len(self.base_outline)):
+            marker = str(self.base_outline[idx] or "").strip().lower()
+            if marker in faq_markers:
+                insert_pos = idx
+                break
+        if insert_pos <= 0:
+            insert_pos = 1
+        if insert_pos >= len(self.base_outline):
+            self.base_outline.append(normalized)
+        else:
+            self.base_outline.insert(insert_pos, normalized)
+
+    def _generate_additional_main_sections(
+        self,
+        *,
+        outline: SkeletonOutline,
+        assembly: SkeletonAssembly,
+        estimate: SkeletonVolumeEstimate,
+        count: int,
+    ) -> List[str]:
+        generated: List[str] = []
+        target_total = max(0, int(count))
+        for _ in range(target_total):
+            new_heading = f"Дополнительный блок {len(outline.main_headings) + 1}"
+            outline.main_headings.append(new_heading)
+            assembly.main_sections.append(None)
+            self._append_main_heading_to_base_outline(new_heading)
+            new_index = len(assembly.main_sections) - 1
+            self._tail_fill_main_sections(
+                indices=[new_index],
+                outline=outline,
+                assembly=assembly,
+                estimate=estimate,
+            )
+            body_text = assembly.main_sections[new_index]
+            if isinstance(body_text, str) and body_text.strip():
+                generated.append(body_text.strip())
+            else:
+                placeholder = (
+                    "Дополнительный раздел будет дополнен подробными рекомендациями "
+                    "в обновлении статьи."
+                )
+                assembly.apply_main(new_index, placeholder, heading=new_heading)
+                generated.append(placeholder)
+        return generated
+
+    def _finalize_main_sections(
+        self,
+        payload: Dict[str, object],
+        *,
+        outline: SkeletonOutline,
+        assembly: SkeletonAssembly,
+        estimate: SkeletonVolumeEstimate,
+    ) -> Dict[str, object]:
+        main_blocks = payload.get("main")
+        if not isinstance(main_blocks, list):
+            main_blocks = []
+        sanitized = [str(item or "").strip() for item in main_blocks if str(item or "").strip()]
+        before_len = len(sanitized)
+        result = list(sanitized)
+        if len(result) > 6:
+            LOGGER.info("LOG:SKELETON_MAIN_TRIMMED from=%d to=6", len(result))
+            result = result[:6]
+        needed = max(0, min(3 - len(result), 3))
+        if needed > 0:
+            additional = self._generate_additional_main_sections(
+                outline=outline,
+                assembly=assembly,
+                estimate=estimate,
+                count=needed,
+            )
+            if additional:
+                result.extend(additional)
+            LOGGER.info(
+                "LOG:SKELETON_MAIN_AUTOFIX needed=%d before=%d after=%d",
+                needed,
+                before_len,
+                len(result),
+            )
+        payload["main"] = result
+        return payload
+
     def _render_skeleton_markdown(self, payload: Dict[str, object]) -> Tuple[str, Dict[str, object]]:
         if not isinstance(payload, dict):
             raise ValueError("Структура скелета не является объектом")
 
         intro = str(payload.get("intro") or "").strip()
-        main = payload.get("main")
+        raw_main = payload.get("main")
+        if not isinstance(raw_main, list):
+            raw_main = []
         conclusion = str(payload.get("conclusion") or "").strip()
         faq = payload.get("faq")
-        if not intro or not conclusion or not isinstance(main, list) or len(main) == 0:
+        if not intro or not conclusion:
             raise ValueError("Скелет не содержит обязательных полей intro/main/conclusion")
 
-        if not 3 <= len(main) <= 6:
-            raise ValueError("Скелет основной части должен содержать 3–6 блоков")
-
-        normalized_main: List[str] = []
-        for idx, item in enumerate(main):
-            if not isinstance(item, str) or not item.strip():
-                raise ValueError(f"Элемент основной части №{idx + 1} пуст")
-            normalized_main.append(item.strip())
+        normalized_main: List[str] = [
+            str(item or "").strip() for item in raw_main if str(item or "").strip()
+        ]
+        if len(normalized_main) > 6:
+            normalized_main = normalized_main[:6]
+        placeholders_needed = max(0, 3 - len(normalized_main))
+        if placeholders_needed:
+            for _ in range(placeholders_needed):
+                normalized_main.append(
+                    "Этот раздел будет расширен детальными рекомендациями в финальной версии статьи."
+                )
+            LOGGER.warning(
+                "LOG:SKELETON_MAIN_PLACEHOLDER applied count=%d",
+                placeholders_needed,
+            )
 
         if not isinstance(faq, list) or len(faq) != 5:
             raise ValueError("Скелет FAQ должен содержать ровно 5 элементов")
 
         normalized_faq: List[Dict[str, str]] = []
         for idx, entry in enumerate(faq, start=1):
             if not isinstance(entry, dict):
                 raise ValueError(f"FAQ элемент №{idx} имеет неверный формат")
             question = str(entry.get("q") or "").strip()
             answer = str(entry.get("a") or "").strip()
             if not question or not answer:
                 raise ValueError(f"FAQ элемент №{idx} пуст")
             normalized_faq.append({"question": question, "answer": answer})
 
         outline = [segment.strip() for segment in self.base_outline if segment.strip()]
         outline = [
             entry
             for entry in outline
             if entry.lower() not in {"faq", "f.a.q.", "вопросы и ответы"}
         ]
         if len(outline) < 3:
             outline = ["Введение", "Основная часть", "Вывод"]
 
         intro_heading = outline[0]
         conclusion_heading = outline[-1]
@@ -1759,50 +2048,66 @@ class DeterministicPipeline:
                     found += 1
             self.keywords_coverage_percent = round(found / len(self.normalized_keywords) * 100, 2)
 
     # ------------------------------------------------------------------
     # Step implementations
     # ------------------------------------------------------------------
     def _run_skeleton(self) -> str:
         self._log(PipelineStep.SKELETON, "running")
         outline = self._prepare_outline()
         estimate = self._predict_skeleton_volume(outline)
         batches = self._build_skeleton_batches(outline)
         assembly = SkeletonAssembly(outline=outline)
         metadata_snapshot: Dict[str, object] = {}
         last_result: Optional[GenerationResult] = None
 
         pending_batches = deque(batches)
         scheduled_main_indices: Set[int] = set()
         parse_none_streaks: Dict[str, int] = {}
         for plan in pending_batches:
             if plan.kind == SkeletonBatchKind.MAIN:
                 scheduled_main_indices.update(plan.indices)
         split_serial = 0
 
         while pending_batches:
             batch = pending_batches.popleft()
+            if batch.kind in (SkeletonBatchKind.FAQ, SkeletonBatchKind.CONCLUSION):
+                filled_main = sum(
+                    1
+                    for body in assembly.main_sections
+                    if isinstance(body, str) and body.strip()
+                )
+                has_pending_main = any(
+                    plan.kind == SkeletonBatchKind.MAIN for plan in pending_batches
+                )
+                if filled_main < 3 and has_pending_main:
+                    LOGGER.info(
+                        "LOG:SCHEDULER_BLOCK main underflow=%d target_min=3 → continue_main",
+                        filled_main,
+                    )
+                    pending_batches.append(batch)
+                    continue
             if not batch.label:
                 batch.label = self._format_batch_label(batch.kind, batch.indices)
             active_indices = list(batch.indices)
             limit_override: Optional[int] = None
             override_to_cap = False
             retries = 0
             consecutive_empty_incomplete = 0
             payload_obj: Optional[object] = None
             metadata_snapshot = {}
             result: Optional[GenerationResult] = None
             last_max_tokens = estimate.start_max_tokens
             continuation_id: Optional[str] = None
             batch_partial = False
             first_attempt_for_batch = True
             best_payload_obj: Optional[object] = None
             best_result: Optional[GenerationResult] = None
             best_metadata_snapshot: Dict[str, object] = {}
             last_reason_lower = ""
 
             while True:
                 messages, format_block = self._build_batch_messages(
                     batch,
                     outline=outline,
                     assembly=assembly,
                     target_indices=active_indices,
@@ -2118,65 +2423,71 @@ class DeterministicPipeline:
                 assembly.apply_conclusion(conclusion_text)
                 if missing_flag:
                     self._tail_fill_batch(
                         batch,
                         outline=outline,
                         assembly=assembly,
                         estimate=estimate,
                         missing_items=[0],
                         metadata=metadata_snapshot,
                     )
 
             self._apply_inline_faq(payload_obj, assembly)
             LOGGER.info(
                 "BATCH_ACCEPT state=%s kind=%s label=%s",
                 "partial" if batch_partial else "complete",
                 batch.kind.value,
                 batch.label,
             )
 
         if not assembly.intro:
             raise PipelineStepError(PipelineStep.SKELETON, "Не удалось получить вводный блок скелета.")
         if not assembly.conclusion:
             raise PipelineStepError(PipelineStep.SKELETON, "Не удалось получить вывод скелета.")
         missing_main = assembly.missing_main_indices()
         if missing_main:
-            raise PipelineStepError(
-                PipelineStep.SKELETON,
-                "Не удалось заполнить все разделы основной части.",
+            LOGGER.warning(
+                "LOG:SKELETON_MAIN_GAPS missing=%s",
+                ",".join(str(idx + 1) for idx in missing_main),
             )
         if outline.has_faq and assembly.missing_faq_count(5):
             raise PipelineStepError(
                 PipelineStep.SKELETON,
                 "Не удалось собрать полный FAQ на этапе скелета.",
             )
 
         payload = assembly.build_payload()
         if outline.has_faq and len(payload.get("faq", [])) > 5:
             payload["faq"] = payload["faq"][:5]
 
         normalized_payload = normalize_skeleton_payload(payload)
+        normalized_payload = self._finalize_main_sections(
+            normalized_payload,
+            outline=outline,
+            assembly=assembly,
+            estimate=estimate,
+        )
         markdown, summary = self._render_skeleton_markdown(normalized_payload)
         snapshot = dict(normalized_payload)
         snapshot["outline"] = summary.get("outline", [])
         if "faq" in summary:
             snapshot["faq"] = summary.get("faq", [])
         self.skeleton_payload = snapshot
         self._skeleton_faq_entries = [
             {"question": entry.get("q", ""), "answer": entry.get("a", "")}
             for entry in normalized_payload.get("faq", [])
         ]
 
         self._check_template_text(markdown, PipelineStep.SKELETON)
         route = last_result.api_route if last_result is not None else "responses"
         LOGGER.info("SKELETON_OK route=%s", route)
         self._update_log(
             PipelineStep.SKELETON,
             "ok",
             length=len(markdown),
             metadata_status=metadata_snapshot.get("status") or "ok",
             **self._metrics(markdown),
         )
         self.checkpoints[PipelineStep.SKELETON] = markdown
         return markdown
 
     def _run_keywords(self, text: str) -> KeywordInjectionResult:

