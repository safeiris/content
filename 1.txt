diff --git a/deterministic_pipeline.py b/deterministic_pipeline.py
index f5bf85a1acba07f953d26b5aedc5ad16b54de6a0..63b410e950cd8a719f4330a4a7079aca7f0654aa 100644
--- a/deterministic_pipeline.py
+++ b/deterministic_pipeline.py
@@ -1,41 +1,46 @@
 """LLM-driven content pipeline with explicit step-level guarantees."""
 
 from __future__ import annotations
 
 import json
 import json
 import logging
 import re
 import textwrap
 import time
 from dataclasses import dataclass, field
 from enum import Enum
 from typing import Dict, Iterable, List, Optional, Sequence, Tuple
 
 from llm_client import GenerationResult, generate as llm_generate
-from keyword_injector import KeywordInjectionResult, build_term_pattern, inject_keywords
+from keyword_injector import (
+    KeywordInjectionResult,
+    LOCK_START_TEMPLATE,
+    build_term_pattern,
+    inject_keywords,
+)
 from length_trimmer import TrimResult, trim_text
 from validators import (
     ValidationError,
     ValidationResult,
     length_no_spaces,
     strip_jsonld,
     validate_article,
 )
 
 
 LOGGER = logging.getLogger("content_factory.pipeline")
 
 FAQ_START = "<!--FAQ_START-->"
 FAQ_END = "<!--FAQ_END-->"
 
 _TEMPLATE_SNIPPETS = [
     "рассматриваем на реальных примерах, чтобы показать связь между цифрами",
     "Отмечаем юридические нюансы, возможные риски и добавляем чек-лист",
     "В выводах собираем план действий, назначаем контрольные даты",
 ]
 
 
 class PipelineStep(str, Enum):
     SKELETON = "skeleton"
     KEYWORDS = "keywords"
@@ -229,115 +234,146 @@ class DeterministicPipeline:
         for snippet in _TEMPLATE_SNIPPETS:
             if snippet in lowered:
                 raise PipelineStepError(step, "Найден служебный шаблонный фрагмент, генерация отклонена.")
 
     def _metrics(self, text: str) -> Dict[str, object]:
         article = strip_jsonld(text)
         chars_no_spaces = length_no_spaces(article)
         keywords_found = 0
         for term in self.normalized_keywords:
             if build_term_pattern(term).search(article):
                 keywords_found += 1
         return {
             "chars_no_spaces": chars_no_spaces,
             "keywords_found": keywords_found,
             "keywords_total": len(self.normalized_keywords),
         }
 
     def _resolve_skeleton_tokens(self) -> int:
         baseline = max(self.max_tokens, self.max_chars + 400)
         if baseline <= 0:
             baseline = self.max_chars + 400
         return min(1500, max(600, baseline))
 
     def _skeleton_contract(self) -> Dict[str, object]:
         outline = [segment.strip() for segment in self.base_outline if segment.strip()]
+        intro = outline[0] if outline else "Введение"
+        outro = outline[-1] if len(outline) > 1 else "Вывод"
+        core_sections = [
+            item
+            for item in outline[1:-1]
+            if item.lower() not in {"faq", "f.a.q.", "вопросы и ответы"}
+        ]
+        if not core_sections:
+            core_sections = ["Основная часть"]
         contract = {
-            "title": "Строго один заголовок первого уровня",
-            "sections": [
-                {
-                    "heading": item,
-                    "goal": "Краткое назначение секции",
-                    "paragraphs": [
-                        "1-3 насыщенных абзаца без буллитов",
-                    ],
-                    "bullets": [],
-                }
-                for item in outline
+            "intro": f"2-3 плотных абзаца для раздела '{intro}'",
+            "main": [
+                f"2-3 абзаца раскрывают тему '{heading}' на практических примерах"
+                for heading in core_sections
             ],
+            "outro": f"1-2 абзаца с выводами и призывом к действию для блока '{outro}'",
         }
         return contract
 
     def _build_skeleton_messages(self) -> List[Dict[str, object]]:
         outline = [segment.strip() for segment in self.base_outline if segment.strip()]
-        contract = json.dumps(self._skeleton_contract(), ensure_ascii=False, indent=2)
+        contract_payload = self._skeleton_contract()
+        contract = json.dumps(contract_payload, ensure_ascii=False, indent=2)
+        main_expected = max(1, len(contract_payload.get("main") or []))
         user_payload = textwrap.dedent(
             f"""
             Сформируй структуру статьи в строгом JSON-формате.
             Требования:
-            1. Соблюдай следующий порядок разделов: {', '.join(outline)}.
-            2. Верни JSON вида {{"title": str, "sections": [{{"heading": str, "paragraphs": [str, ...]}}]}}.
-            3. Каждый paragraphs содержит 2-3 осмысленных абзаца по 3-4 предложения без приветствий.
-            4. Не добавляй FAQ и маркеры; только данные для отрисовки.
-            5. Не используй Markdown и комментарии.
+            1. Соблюдай порядок разделов: {', '.join(outline) if outline else 'Введение, Основная часть, Вывод'}.
+            2. Верни JSON вида {{"intro": str, "main": [str, ...], "outro": str}} без дополнительных ключей.
+            3. main должен содержать {main_expected} элемента — по одному на каждый раздел основной части.
+            4. Каждый элемент intro/main/outro содержит 2-3 осмысленных абзаца по 3-4 предложения, без Markdown и приветствий.
+            5. Не добавляй FAQ, разметку, комментарии и служебные подписи.
             Образец структуры:
             {contract}
             """
         ).strip()
         messages = list(self.messages)
         messages.append({"role": "user", "content": user_payload})
         return messages
 
     def _render_skeleton_markdown(self, payload: Dict[str, object]) -> Tuple[str, Dict[str, object]]:
         if not isinstance(payload, dict):
             raise ValueError("Структура скелета не является объектом")
-        title = str(payload.get("title") or "").strip()
-        sections = payload.get("sections")
-        if not title or not isinstance(sections, list) or not sections:
+
+        intro = str(payload.get("intro") or "").strip()
+        main = payload.get("main")
+        outro = str(payload.get("outro") or "").strip()
+        if not intro or not outro or not isinstance(main, list) or not main:
             raise ValueError("Скелет не содержит обязательных полей")
-        outline = []
-        lines: List[str] = [f"# {title}", ""]
-        for section in sections:
-            if not isinstance(section, dict):
-                raise ValueError("Секция имеет некорректный формат")
-            heading = str(section.get("heading") or "").strip()
-            paragraphs = section.get("paragraphs")
-            if not heading or not isinstance(paragraphs, list) or not paragraphs:
-                raise ValueError("Секция неполная")
-            outline.append(heading)
+
+        for idx, item in enumerate(main):
+            if not isinstance(item, str) or not item.strip():
+                raise ValueError(f"Элемент основной части №{idx + 1} пуст")
+
+        outline = [segment.strip() for segment in self.base_outline if segment.strip()]
+        outline = [
+            entry
+            for entry in outline
+            if entry.lower() not in {"faq", "f.a.q.", "вопросы и ответы"}
+        ]
+        if len(outline) < 3:
+            outline = ["Введение", "Основная часть", "Вывод"]
+
+        intro_heading = outline[0]
+        outro_heading = outline[-1]
+        main_headings = outline[1:-1]
+        if not main_headings:
+            main_headings = ["Основная часть"]
+        if len(main_headings) != len(main):
+            raise ValueError(
+                "Количество блоков в основной части не совпадает с ожиданиями по структуре"
+            )
+
+        lines: List[str] = [f"# {self.topic}", ""]
+
+        def _append_section(heading: str, content: str) -> None:
+            paragraphs = [part.strip() for part in re.split(r"\n{2,}", content) if part.strip()]
+            if not paragraphs:
+                raise ValueError(f"Раздел '{heading}' пуст")
             lines.append(f"## {heading}")
             for paragraph in paragraphs:
-                text = str(paragraph).strip()
-                if not text:
-                    continue
-                lines.append(text)
+                lines.append(paragraph)
                 lines.append("")
+
+        _append_section(intro_heading, intro)
+        for heading, body in zip(main_headings, main):
+            _append_section(heading, body)
+        _append_section(outro_heading, outro)
+
         lines.append("## FAQ")
         lines.append(FAQ_START)
         lines.append(FAQ_END)
         markdown = "\n".join(lines).strip()
-        return markdown, {"title": title, "outline": outline}
+        outline_summary = [intro_heading, *main_headings, outro_heading]
+        return markdown, {"outline": outline_summary}
 
     def _render_faq_markdown(self, entries: Sequence[Dict[str, str]]) -> str:
         lines: List[str] = []
         for index, entry in enumerate(entries, start=1):
             question = entry.get("question", "").strip()
             answer = entry.get("answer", "").strip()
             lines.append(f"**Вопрос {index}.** {question}")
             lines.append(f"**Ответ.** {answer}")
             lines.append("")
         return "\n".join(lines).strip()
 
     def _build_jsonld(self, entries: Sequence[Dict[str, str]]) -> str:
         payload = {
             "@context": "https://schema.org",
             "@type": "FAQPage",
             "mainEntity": [
                 {
                     "@type": "Question",
                     "name": entry.get("question", ""),
                     "acceptedAnswer": {"@type": "Answer", "text": entry.get("answer", "")},
                 }
                 for entry in entries
             ],
         }
         compact = json.dumps(payload, ensure_ascii=False, separators=(",", ":"))
@@ -462,51 +498,53 @@ class DeterministicPipeline:
                 LOGGER.warning(
                     "SKELETON_RETRY_incomplete attempt=%d status=%s reason=%s",
                     attempt,
                     status,
                     metadata_snapshot.get("incomplete_reason") or "",
                 )
                 skeleton_tokens = max(600, int(skeleton_tokens * 0.9))
                 continue
             raw_text = result.text.strip()
             if not raw_text:
                 last_error = PipelineStepError(PipelineStep.SKELETON, "Модель вернула пустой ответ.")
                 LOGGER.warning("SKELETON_RETRY_json_error attempt=%d error=empty", attempt)
                 skeleton_tokens = max(600, int(skeleton_tokens * 0.9))
                 continue
             try:
                 payload = json.loads(raw_text)
                 LOGGER.info("SKELETON_JSON_OK attempt=%d", attempt)
             except json.JSONDecodeError as exc:
                 LOGGER.warning("SKELETON_JSON_INVALID attempt=%d error=%s", attempt, exc)
                 LOGGER.warning("SKELETON_RETRY_json_error attempt=%d", attempt)
                 skeleton_tokens = max(600, int(skeleton_tokens * 0.9))
                 last_error = PipelineStepError(PipelineStep.SKELETON, "Ответ модели не является корректным JSON.")
                 continue
             try:
                 markdown, summary = self._render_skeleton_markdown(payload)
-                self.skeleton_payload = payload
+                snapshot = dict(payload)
+                snapshot["outline"] = summary.get("outline", [])
+                self.skeleton_payload = snapshot
                 LOGGER.info("SKELETON_RENDERED_WITH_MARKERS outline=%s", ",".join(summary.get("outline", [])))
             except Exception as exc:  # noqa: BLE001
                 last_error = PipelineStepError(PipelineStep.SKELETON, str(exc))
                 LOGGER.warning("SKELETON_RETRY_json_error attempt=%d error=%s", attempt, exc)
                 payload = None
                 skeleton_tokens = max(600, int(skeleton_tokens * 0.9))
                 markdown = None
 
         if markdown is None:
             if last_error:
                 raise last_error
             raise PipelineStepError(
                 PipelineStep.SKELETON,
                 "Не удалось получить корректный скелет статьи после нескольких попыток.",
             )
 
         if FAQ_START not in markdown or FAQ_END not in markdown:
             raise PipelineStepError(PipelineStep.SKELETON, "Не удалось вставить маркеры FAQ на этапе скелета.")
 
         self._check_template_text(markdown, PipelineStep.SKELETON)
         self._update_log(
             PipelineStep.SKELETON,
             "ok",
             length=len(markdown),
             metadata_status=metadata_snapshot.get("status") or "ok",
@@ -549,50 +587,71 @@ class DeterministicPipeline:
         self._update_log(
             PipelineStep.FAQ,
             "ok",
             entries=[entry["question"] for entry in entries],
             **self._metrics(merged_text),
         )
         self.checkpoints[PipelineStep.FAQ] = merged_text
         return merged_text
 
     def _run_trim(self, text: str) -> TrimResult:
         self._log(PipelineStep.TRIM, "running")
         reserve = self.jsonld_reserve if self.jsonld else 0
         target_max = max(self.min_chars, self.max_chars - reserve)
         result = trim_text(
             text,
             min_chars=self.min_chars,
             max_chars=target_max,
             protected_blocks=self.locked_terms,
         )
         current_length = length_no_spaces(result.text)
         if current_length < self.min_chars or current_length > self.max_chars:
             raise PipelineStepError(
                 PipelineStep.TRIM,
                 f"Объём после трима вне диапазона {self.min_chars}–{self.max_chars} (без пробелов).",
             )
+
+        missing_locks = [
+            term
+            for term in self.normalized_keywords
+            if LOCK_START_TEMPLATE.format(term=term) not in result.text
+        ]
+        if missing_locks:
+            raise PipelineStepError(
+                PipelineStep.TRIM,
+                "После тримминга потеряны ключевые фразы: " + ", ".join(sorted(missing_locks)),
+            )
+
+        faq_block = ""
+        if FAQ_START in result.text and FAQ_END in result.text:
+            faq_block = result.text.split(FAQ_START, 1)[1].split(FAQ_END, 1)[0]
+        faq_pairs = re.findall(r"\*\*Вопрос\s+\d+\.\*\*", faq_block)
+        if len(faq_pairs) != 5:
+            raise PipelineStepError(
+                PipelineStep.TRIM,
+                "FAQ должен содержать ровно 5 вопросов после тримминга.",
+            )
         self._update_log(
             PipelineStep.TRIM,
             "ok",
             removed=len(result.removed_paragraphs),
             **self._metrics(result.text),
         )
         self.checkpoints[PipelineStep.TRIM] = result.text
         return result
 
     # ------------------------------------------------------------------
     # Public API
     # ------------------------------------------------------------------
     def run(self) -> PipelineState:
         text = self._run_skeleton()
         keyword_result = self._run_keywords(text)
         faq_text = self._run_faq(keyword_result.text)
         trim_result = self._run_trim(faq_text)
         combined_text = trim_result.text
         if self.jsonld and self.jsonld_requested:
             combined_text = f"{combined_text.rstrip()}\n\n{self.jsonld}\n"
         try:
             validation = validate_article(
                 combined_text,
                 keywords=self.keywords,
                 min_chars=self.min_chars,
diff --git a/orchestrate.py b/orchestrate.py
index d405431dd205933b4222683bf13a4bf009e4d37b..2eb014a27ae2fbba18a14bbdf8999ed311e717f5 100644
--- a/orchestrate.py
+++ b/orchestrate.py
@@ -541,58 +541,58 @@ def gather_health_status(theme: Optional[str]) -> Dict[str, Any]:
 
     api_key = (os.getenv("OPENAI_API_KEY") or OPENAI_API_KEY).strip()
     if not api_key:
         checks["openai_key"] = {"ok": False, "message": "OPENAI_API_KEY не найден"}
         ok = False
     else:
         masked = f"{api_key[:4]}***{api_key[-4:]}" if len(api_key) > 8 else "*" * len(api_key)
         try:
             response = httpx.get(
                 "https://api.openai.com/v1/models",
                 headers={"Authorization": f"Bearer {api_key}"},
                 timeout=5.0,
             )
             if response.status_code == 200:
                 checks["openai_key"] = {"ok": True, "message": f"Ключ активен ({masked})"}
             else:
                 ok = False
                 checks["openai_key"] = {"ok": False, "message": f"HTTP {response.status_code} при проверке ключа ({masked})"}
         except httpx.HTTPError as exc:
             ok = False
             checks["openai_key"] = {"ok": False, "message": f"Ошибка проверки ключа: {exc}"}
 
         if checks.get("openai_key", {}).get("ok"):
             try:
                 probe_messages = [
-                    {"role": "system", "content": "Ты проверка готовности. Ответь одним словом."},
-                    {"role": "user", "content": "Скажи PING"},
+                    {"role": "system", "content": "Ты проверка готовности. Ответь строго словом PING."},
+                    {"role": "user", "content": "Ответь словом PING"},
                 ]
                 ping_result = llm_generate(
                     probe_messages,
                     model=DEFAULT_MODEL,
                     temperature=0.0,
-                    max_tokens=4,
+                    max_tokens=12,
                     timeout_s=10,
                 )
                 reply = (ping_result.text or "").strip().lower()
                 ping_ok = reply.startswith("ping")
                 if not ping_ok:
                     ok = False
                     checks["llm_ping"] = {
                         "ok": False,
                         "message": f"Неожиданный ответ модели: {ping_result.text[:32]}",
                     }
                 else:
                     checks["llm_ping"] = {"ok": True, "message": "Ответ PING получен"}
             except Exception as exc:  # noqa: BLE001
                 ok = False
                 checks["llm_ping"] = {"ok": False, "message": f"LLM недоступна: {exc}"}
 
     artifacts_dir = Path("artifacts")
     try:
         artifacts_dir.mkdir(parents=True, exist_ok=True)
         probe = artifacts_dir / ".write_check"
         probe.write_text("ok", encoding="utf-8")
         probe.unlink()
         checks["artifacts_writable"] = {"ok": True, "message": "Запись в artifacts/ доступна"}
     except Exception as exc:  # noqa: BLE001
         ok = False
diff --git a/tests/test_orchestrate_utils.py b/tests/test_orchestrate_utils.py
index 876d6b5deb2c0b9af022d102c2b8cabacf7937e2..003951276dfd77913a05f0a4402ecd20e6f3ff6d 100644
--- a/tests/test_orchestrate_utils.py
+++ b/tests/test_orchestrate_utils.py
@@ -104,62 +104,75 @@ def test_validator_length_ignores_jsonld():
         f"{LOCK_START_TEMPLATE.format(term='ключ')}ключ<!--LOCK_END--> фиксирует термин.\n\n"
         "## FAQ\n\n<!--FAQ_START-->\n"
         f"{faq_block}\n"
         "<!--FAQ_END-->\n"
         "<script type=\"application/ld+json\">\n"
         f"{json.dumps(payload, ensure_ascii=False)}\n"
         "</script>"
     )
     article_no_jsonld = strip_jsonld(article)
     base_length = len("".join(article_no_jsonld.split()))
     full_length = len("".join(article.split()))
     assert full_length > base_length
     min_chars = max(10, base_length - 5)
     max_chars = base_length + 5
     result = validate_article(article, keywords=["ключ"], min_chars=min_chars, max_chars=max_chars)
     assert result.length_ok
     assert result.jsonld_ok
 
 
 def _stub_llm(monkeypatch):
     base_paragraph = (
         "Абзац с анализом показателей и практическими советами для семейного бюджета. "
         "Расчёт коэффициентов сопровождаем примерами и перечнем действий."
     )
     outline = ["Введение", "Аналитика", "Решения"]
-    skeleton_sections = []
-    for heading in outline:
-        paragraphs = []
-        for idx in range(6):
-            paragraphs.append(
-                f"{base_paragraph} {heading} блок {idx + 1} раскрывает практическое значение ключевых метрик и указывает конкретные шаги, подкреплённые цифрами и контрольными датами."
-            )
-            paragraphs.append("Расписываем временные рамки, ответственных лиц и цифровые инструменты, которые удерживают контроль над бюджетом и помогают выдерживать долговую нагрузку в безопасных пределах.")
-        skeleton_sections.append({"heading": heading, "paragraphs": paragraphs})
+    intro_block = []
+    for idx in range(4):
+        intro_block.append(
+            f"{base_paragraph} Введение блок {idx + 1} показывает, как сформировать картину текущей ситуации и определить безопасные пределы долга."
+        )
+    intro_text = "\n\n".join(intro_block)
+
+    main_blocks = []
+    for idx in range(5):
+        main_blocks.append(
+            f"{base_paragraph} Аналитика блок {idx + 1} фокусируется на цифрах, добавляет формулы и объясняет, как применять их на практике."
+        )
+    main_text = "\n\n".join(main_blocks)
+
+    outro_parts = []
+    for idx in range(3):
+        outro_parts.append(
+            f"{base_paragraph} Решения блок {idx + 1} переводит выводы в план действий, перечисляет контрольные даты и роли участников."
+        )
+    outro_text = "\n\n".join(outro_parts)
+
     skeleton_payload = {
-        "title": "Долговая нагрузка семьи: практическое руководство",
-        "sections": skeleton_sections,
+        "intro": intro_text,
+        "main": [main_text],
+        "outro": outro_text,
     }
     skeleton_text = json.dumps(skeleton_payload, ensure_ascii=False)
     faq_payload = {
         "faq": [
             {
                 "question": "Как определить допустимую долговую нагрузку?",
                 "answer": "Сравните платежи с ежемесячным доходом и удерживайте коэффициент не выше 30–35%.",
             },
             {
                 "question": "Какие данные нужны для расчёта?",
                 "answer": "Соберите сведения по кредитам, страховым взносам и коммунальным платежам за последний год.",
             },
             {
                 "question": "Что делать при превышении порога?",
                 "answer": "Пересмотрите график платежей, договоритесь о реструктуризации и выделите обязательные траты.",
             },
             {
                 "question": "Как планировать резерв?",
                 "answer": "Откладывайте не менее двух ежемесячных платежей на отдельный счёт с быстрым доступом.",
             },
             {
                 "question": "Какие сервисы помогают контролю?",
                 "answer": "Используйте банковские дашборды и напоминания календаря, чтобы отслеживать даты и суммы.",
             },
         ]
diff --git a/validators.py b/validators.py
index 7a2ca00c80a8cacafa1c78643dfb557c0192c34d..bd422ec787f6ff86947d7770a97d4d7c2cd72fb5 100644
--- a/validators.py
+++ b/validators.py
@@ -72,60 +72,69 @@ def _jsonld_valid(text: str) -> bool:
     for entry in entities:
         if not isinstance(entry, dict):
             return False
         if entry.get("@type") != "Question":
             return False
         answer = entry.get("acceptedAnswer")
         if not isinstance(answer, dict) or answer.get("@type") != "Answer":
             return False
         if not str(entry.get("name", "")).strip():
             return False
         if not str(answer.get("text", "")).strip():
             return False
     return True
 
 
 def _skeleton_status(
     skeleton_payload: Optional[Dict[str, object]],
     text: str,
 ) -> Tuple[bool, Optional[str]]:
     if skeleton_payload is None:
         if "## FAQ" in text and _FAQ_START in text and _FAQ_END in text:
             return True, None
         return False, "В markdown нет заголовка FAQ и маркеров <!--FAQ_START/END-->."
     if not isinstance(skeleton_payload, dict):
         return False, "Данные скелета не получены или имеют неверный формат."
-    sections = skeleton_payload.get("sections")
-    if not isinstance(sections, list) or not sections:
-        return False, "Скелет не содержит секций."
-    for section in sections:
-        if not isinstance(section, dict):
-            return False, "Секция скелета повреждена."
-        heading = str(section.get("heading") or "").strip()
-        paragraphs = section.get("paragraphs")
-        if not heading or not isinstance(paragraphs, list) or not paragraphs:
-            return False, "Секция скелета заполнена не полностью."
+
+    intro = str(skeleton_payload.get("intro") or "").strip()
+    outro = str(skeleton_payload.get("outro") or "").strip()
+    main = skeleton_payload.get("main")
+    if not intro or not outro or not isinstance(main, list) or not main:
+        return False, "Скелет не содержит обязательных полей intro/main/outro."
+    for idx, item in enumerate(main):
+        if not isinstance(item, str) or not item.strip():
+            return False, f"Блок основной части №{idx + 1} пуст."
+
+    outline = skeleton_payload.get("outline")
+    if outline and isinstance(outline, list):
+        normalized_outline = [str(entry).strip() for entry in outline if str(entry).strip()]
+    else:
+        normalized_outline = []
+
+    expected_main = max(1, len(normalized_outline) - 2) if normalized_outline else len(main)
+    if len(main) != expected_main:
+        return False, "Количество блоков основной части не совпадает с ожидаемым."
     if "## FAQ" not in text or _FAQ_START not in text or _FAQ_END not in text:
         return False, "В markdown нет заголовка FAQ и маркеров <!--FAQ_START/END-->."
     return True, None
 
 
 def validate_article(
     text: str,
     *,
     keywords: Iterable[str],
     min_chars: int,
     max_chars: int,
     skeleton_payload: Optional[Dict[str, object]] = None,
 ) -> ValidationResult:
     length = _length_no_spaces(text)
     skeleton_ok, skeleton_message = _skeleton_status(skeleton_payload, text)
 
     normalized_keywords = [str(term).strip() for term in keywords if str(term).strip()]
     missing: List[str] = []
     for term in normalized_keywords:
         lock_token = LOCK_START_TEMPLATE.format(term=term)
         if lock_token not in text:
             missing.append(term)
     keywords_ok = len(missing) == 0
 
     faq_pairs = _faq_pairs(text)

