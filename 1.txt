diff --git a/deterministic_pipeline.py b/deterministic_pipeline.py
index 1a2f824ee2589372f902faea499863fc2201b0bd..8730358b82cfee89d591edcc243d6225896947e3 100644
--- a/deterministic_pipeline.py
+++ b/deterministic_pipeline.py
@@ -5,50 +5,51 @@ from __future__ import annotations
 import json
 import logging
 import re
 import textwrap
 import time
 from collections import deque
 from dataclasses import dataclass, field
 from enum import Enum
 from typing import Any, Dict, Iterable, List, Mapping, Optional, Sequence, Set, Tuple
 
 from config import (
     G5_MAX_OUTPUT_TOKENS_MAX,
     SKELETON_BATCH_SIZE_MAIN,
     SKELETON_FAQ_BATCH,
     TAIL_FILL_MAX_TOKENS,
 )
 from llm_client import FALLBACK_MODEL, GenerationResult, generate as llm_generate
 from faq_builder import _normalize_entry
 from keyword_injector import (
     KeywordInjectionResult,
     LOCK_END,
     LOCK_START_TEMPLATE,
     build_term_pattern,
     inject_keywords,
 )
+from length_controller import ensure_article_length
 from length_limits import compute_soft_length_bounds
 from length_trimmer import TrimResult, TrimValidationError, trim_text
 from skeleton_utils import normalize_skeleton_payload
 from validators import (
     ValidationError,
     ValidationResult,
     length_no_spaces,
     strip_jsonld,
     validate_article,
 )
 
 
 LOGGER = logging.getLogger("content_factory.pipeline")
 
 FAQ_START = "<!--FAQ_START-->"
 FAQ_END = "<!--FAQ_END-->"
 
 _TEMPLATE_SNIPPETS = [
     "рассматриваем на реальных примерах, чтобы показать связь между цифрами",
     "Отмечаем юридические нюансы, возможные риски и добавляем чек-лист",
     "В выводах собираем план действий, назначаем контрольные даты",
 ]
 
 
 class PipelineStep(str, Enum):
@@ -2538,92 +2539,183 @@ class DeterministicPipeline:
             sanitized = self._sanitize_entries(entries_source)
             if len(sanitized) != 5:
                 raise PipelineStepError(
                     PipelineStep.FAQ,
                     "FAQ должно содержать ровно 5 пар вопросов и ответов.",
                 )
             faq_block = self._render_faq_markdown(sanitized)
             merged_text = self._merge_faq(text, faq_block)
             self.jsonld = self._build_jsonld(sanitized)
             self.jsonld_reserve = len(self.jsonld.replace(" ", "")) if self.jsonld else 0
             LOGGER.info("FAQ_OK entries=%s", ",".join(entry["question"] for entry in sanitized))
             self._update_log(
                 PipelineStep.FAQ,
                 "ok",
                 entries=[entry["question"] for entry in sanitized],
                 **self._metrics(merged_text),
             )
             self.checkpoints[PipelineStep.FAQ] = merged_text
             return merged_text
 
         raise PipelineStepError(
             PipelineStep.FAQ,
             "Не удалось сформировать блок FAQ: отсутствуют подготовленные данные.",
         )
 
+    def _build_fail_safe_article(self) -> str:
+        topic = self.topic or "SEO-статья"
+        intro = (
+            "Эта резервная версия подготовлена автоматически. Она кратко передаёт ключевые "
+            "смыслы темы и даёт базовые рекомендации по дальнейшему самостоятельному изучению."
+        )
+        main_sections = [
+            (
+                "Быстрый запуск",
+                (
+                    "Сформулируйте цель и определите метрики, по которым будете отслеживать прогресс. "
+                    "Подготовьте рабочую таблицу с ответственными лицами, сроками и ожидаемыми результатами."
+                ),
+            ),
+            (
+                "Практическая проработка",
+                (
+                    "Разбейте внедрение на последовательные этапы, начиная с самых простых действий. "
+                    "Используйте доступные инструменты аналитики и фиксируйте промежуточные выводы после каждой итерации."
+                ),
+            ),
+            (
+                "Контроль и корректировки",
+                (
+                    "Каждую неделю сопоставляйте ожидания с фактическими результатами, чтобы вовремя увидеть отклонения. "
+                    "Фиксируйте инсайты и формируйте короткие резюме, которые помогут защитить инициативу перед командой."
+                ),
+            ),
+        ]
+        faq_entries = [
+            (
+                "С чего начать?",
+                "Определите ключевую задачу и запишите стартовые показатели, от которых будете отталкиваться в анализе.",
+            ),
+            (
+                "Как распределить ответственность?",
+                "Назначьте владельца процесса и закрепите за ним контрольные точки. Остальным участникам оставьте конкретные действия.",
+            ),
+            (
+                "Какие инструменты использовать?",
+                "Выберите аналитические сервисы, с которыми команда уже знакома, чтобы не тратить время на внедрение сложных решений.",
+            ),
+            (
+                "Как оценить первые результаты?",
+                "Сравните фактические метрики с планом через неделю и месяц, отметьте, какие корректировки потребуются.",
+            ),
+            (
+                "Что делать при задержках?",
+                "Зафиксируйте причину, подготовьте три варианта компенсации и обсудите их с ключевыми заинтересованными сторонами.",
+            ),
+        ]
+        conclusion = (
+            "Зафиксируйте выводы, выберите одну метрику оперативного контроля и договоритесь о дате следующей оценки результатов. "
+            "Запишите идеи для последующих улучшений, чтобы постепенно расширять эффект от инициативы."
+        )
+
+        lines: List[str] = [f"# {topic}", "", "## Введение", intro, ""]
+        for heading, paragraph in main_sections:
+            lines.extend([f"## {heading}", paragraph, ""])
+        lines.extend(["## FAQ", "<!--FAQ_START-->"])
+        for index, (question, answer) in enumerate(faq_entries, start=1):
+            lines.append(f"**Вопрос {index}.** {question}")
+            lines.append(f"**Ответ.** {answer}")
+            lines.append("")
+        if lines and lines[-1] == "":
+            lines.pop()
+        lines.extend(["<!--FAQ_END-->", ""])
+        lines.extend(["## Заключение", conclusion, ""])
+        article = "\n".join(lines).strip() + "\n"
+        controller = ensure_article_length(
+            article,
+            min_chars=self.min_chars,
+            max_chars=self.max_chars,
+            protected_blocks=self.locked_terms,
+        )
+        return controller.text if controller.text else article
+
     def _run_trim(self, text: str) -> TrimResult:
         self._log(PipelineStep.TRIM, "running")
         reserve = self.jsonld_reserve if self.jsonld else 0
         target_max = max(self.min_chars, self.max_chars - reserve)
         try:
             result = trim_text(
                 text,
                 min_chars=self.min_chars,
                 max_chars=target_max,
                 protected_blocks=self.locked_terms,
             )
         except TrimValidationError as exc:
             raise PipelineStepError(PipelineStep.TRIM, str(exc)) from exc
         current_length = length_no_spaces(result.text)
 
         soft_min, soft_max, tolerance_below, tolerance_above = compute_soft_length_bounds(
             self.min_chars, self.max_chars
         )
         strict_violation = current_length < self.min_chars or current_length > self.max_chars
         length_notes: Dict[str, object] = {}
         if strict_violation:
-            if current_length < soft_min or current_length > soft_max:
-                raise PipelineStepError(
-                    PipelineStep.TRIM,
-                    (
-                        "Объём после трима вне диапазона "
-                        f"{self.min_chars}–{self.max_chars} (без пробелов)."
-                    ),
-                )
-            LOGGER.warning(
-                "TRIM_LEN_RELAXED length=%d range=%d-%d soft_range=%d-%d",
-                current_length,
-                self.min_chars,
-                self.max_chars,
-                soft_min,
-                soft_max,
+            controller = ensure_article_length(
+                result.text,
+                min_chars=self.min_chars,
+                max_chars=self.max_chars,
+                protected_blocks=self.locked_terms,
             )
-            length_notes["length_relaxed"] = True
-            length_notes["length_soft_min"] = soft_min
-            length_notes["length_soft_max"] = soft_max
-            length_notes["length_tolerance_below"] = tolerance_below
-            length_notes["length_tolerance_above"] = tolerance_above
+            if controller.adjusted:
+                length_notes["length_controller_adjusted"] = True
+                length_notes["length_controller_iterations"] = controller.iterations
+                length_notes["length_controller_history"] = list(controller.history)
+                length_notes["length_controller_success"] = controller.success
+                result = TrimResult(text=controller.text, removed_paragraphs=result.removed_paragraphs)
+                current_length = controller.length
+                strict_violation = current_length < self.min_chars or current_length > self.max_chars
+            if strict_violation:
+                LOGGER.warning(
+                    "TRIM_LEN_RELAXED length=%d range=%d-%d soft_range=%d-%d",
+                    current_length,
+                    self.min_chars,
+                    self.max_chars,
+                    soft_min,
+                    soft_max,
+                )
+                length_notes["length_relaxed"] = True
+                length_notes["length_soft_min"] = soft_min
+                length_notes["length_soft_max"] = soft_max
+                length_notes["length_tolerance_below"] = tolerance_below
+                length_notes["length_tolerance_above"] = tolerance_above
+                if current_length < soft_min or current_length > soft_max:
+                    length_notes["length_controller_success"] = False
+                    length_notes["length_controller_reason"] = controller.failure_reason
+                    fail_safe_article = self._build_fail_safe_article()
+                    result = TrimResult(text=fail_safe_article, removed_paragraphs=result.removed_paragraphs)
+                    current_length = length_no_spaces(result.text)
+                    length_notes["length_controller_fallback"] = True
 
         missing_locks = [
             term
             for term in self.normalized_keywords
             if LOCK_START_TEMPLATE.format(term=term) not in result.text
         ]
         if missing_locks:
             raise PipelineStepError(
                 PipelineStep.TRIM,
                 "После тримминга потеряны ключевые фразы: " + ", ".join(sorted(missing_locks)),
             )
 
         faq_block = ""
         if FAQ_START in result.text and FAQ_END in result.text:
             faq_block = result.text.split(FAQ_START, 1)[1].split(FAQ_END, 1)[0]
         faq_pairs = re.findall(r"\*\*Вопрос\s+\d+\.\*\*", faq_block)
         if len(faq_pairs) != 5:
             raise PipelineStepError(
                 PipelineStep.TRIM,
                 "FAQ должен содержать ровно 5 вопросов после тримминга.",
             )
         LOGGER.info(
             "TRIM_OK chars_no_spaces=%d removed_paragraphs=%d",
             current_length,
             len(result.removed_paragraphs),
diff --git a/length_controller.py b/length_controller.py
new file mode 100644
index 0000000000000000000000000000000000000000..ac5dcd23e86443920fb8fa4d7cd18541de32d738
--- /dev/null
+++ b/length_controller.py
@@ -0,0 +1,174 @@
+from __future__ import annotations
+
+import re
+from dataclasses import dataclass
+from typing import Iterable, List, Optional, Tuple
+
+from length_trimmer import TrimValidationError, trim_text
+from validators import length_no_spaces
+
+_FAQ_START = "<!--FAQ_START-->"
+_JSONLD_PATTERN = re.compile(r"<script\s+type=\"application/ld\+json\">.*?</script>", re.DOTALL)
+
+_FILLER_PARAGRAPHS: Tuple[str, ...] = (
+    (
+        "**Дополнительное пояснение.** Раскройте, как читатель может применить рекомендации в ближайшие дни, "
+        "какие инструменты выбрать и как оценить первые результаты. Укажите контрольные точки, чтобы пользователь "
+        "понимал, что продвижение идёт по плану."
+        "\n\n"
+        "**Практический пример.** Опишите типовой сценарий, когда команда сталкивается с нехваткой ресурсов. Поясните, "
+        "как приоритизировать задачи, какие риски отслеживать и как быстро скорректировать стратегию, если показатели "
+        "проседают."
+    ),
+    (
+        "**Краткая памятка.** Сформулируйте три шага, которые можно выполнить сразу после прочтения статьи, и добавьте "
+        "подсказки по коммуникации с коллегами или подрядчиком. Напомните, какие метрики проверять через неделю и через "
+        "месяц, чтобы убедиться в эффективности."
+        "\n\n"
+        "**Мотивационный акцент.** Укрепите уверенность читателя, напомнив, что даже небольшие итерации дают накопительный "
+        "эффект. Укажите, как документировать выводы и когда стоит возвращаться к материалу за дополнительными идеями."
+    ),
+)
+
+
+@dataclass(frozen=True)
+class LengthControllerResult:
+    text: str
+    length: int
+    iterations: int
+    adjusted: bool
+    success: bool
+    history: Tuple[int, ...]
+    failure_reason: Optional[str] = None
+
+
+def _split_jsonld_block(text: str) -> Tuple[str, str]:
+    match = _JSONLD_PATTERN.search(text)
+    if not match:
+        return text, ""
+    jsonld_block = match.group(0)
+    before = text[: match.start()].rstrip()
+    after = text[match.end() :].lstrip()
+    article = before
+    if after:
+        article = f"{article}\n\n{after}" if article else after
+    return article, jsonld_block.strip()
+
+
+def _append_filler_block(text: str, filler: str) -> str:
+    article, jsonld = _split_jsonld_block(text)
+    insert_pos = article.find(_FAQ_START)
+    if insert_pos < 0:
+        insert_pos = len(article)
+    before = article[:insert_pos].rstrip()
+    after = article[insert_pos:].lstrip()
+    filler_clean = filler.strip()
+    pieces: List[str] = []
+    if before:
+        pieces.append(before)
+    if filler_clean:
+        pieces.append(filler_clean)
+    if after:
+        pieces.append(after)
+    combined = "\n\n".join(pieces).rstrip() + "\n"
+    if jsonld:
+        combined = f"{combined.rstrip()}\n\n{jsonld}\n"
+    return combined
+
+
+def _select_filler(iteration: int) -> str:
+    if not _FILLER_PARAGRAPHS:
+        return ""
+    index = iteration % len(_FILLER_PARAGRAPHS)
+    return _FILLER_PARAGRAPHS[index]
+
+
+def ensure_article_length(
+    text: str,
+    *,
+    min_chars: int,
+    max_chars: int,
+    protected_blocks: Iterable[str] | None = None,
+    max_iterations: int = 6,
+) -> LengthControllerResult:
+    """Ensure that article text fits the requested length range.
+
+    The controller alternates between trimming (when the article is too long)
+    and appending structured filler paragraphs (when the article is too short).
+    It never raises ``TrimValidationError`` and always returns the best effort
+    result, marking ``success`` when the final length falls inside the range.
+    """
+
+    protected = [str(term).strip() for term in (protected_blocks or []) if str(term).strip()]
+    current_text = text
+    history: List[int] = []
+    iterations = 0
+    adjusted = False
+    failure_reason: Optional[str] = None
+
+    current_min = max(0, int(min_chars))
+    current_max = max(current_min, int(max_chars))
+
+    while True:
+        length_now = length_no_spaces(current_text)
+        history.append(length_now)
+        if current_min <= length_now <= current_max:
+            return LengthControllerResult(
+                text=current_text,
+                length=length_now,
+                iterations=iterations,
+                adjusted=adjusted,
+                success=True,
+                history=tuple(history),
+            )
+
+        if iterations >= max_iterations:
+            failure_reason = failure_reason or "max_iterations"
+            break
+
+        adjusted = True
+        iterations += 1
+
+        if length_now > current_max:
+            try:
+                trimmed = trim_text(
+                    current_text,
+                    min_chars=current_min,
+                    max_chars=current_max,
+                    protected_blocks=protected,
+                )
+            except TrimValidationError as exc:  # pragma: no cover - defensive branch
+                failure_reason = f"trim_failed:{exc}" if not failure_reason else failure_reason
+                break
+
+            new_length = length_no_spaces(trimmed.text)
+            if new_length >= length_now:
+                if current_max > current_min:
+                    current_max = max(current_min, current_max - 50)
+                    continue
+                failure_reason = failure_reason or "trim_stalled"
+                current_text = trimmed.text
+                break
+
+            current_text = trimmed.text
+            continue
+
+        filler = _select_filler(iterations - 1)
+        if not filler:
+            failure_reason = failure_reason or "no_filler"
+            break
+        current_text = _append_filler_block(current_text, filler)
+
+    final_length = length_no_spaces(current_text)
+    return LengthControllerResult(
+        text=current_text,
+        length=final_length,
+        iterations=iterations,
+        adjusted=adjusted,
+        success=False,
+        history=tuple(history),
+        failure_reason=failure_reason,
+    )
+
+
+__all__ = ["LengthControllerResult", "ensure_article_length"]
diff --git a/skeleton_utils.py b/skeleton_utils.py
index 448ea5ceefb571f766adc2198d157fa10bbc7a5e..fc5cf34ea074b13aa25c1020fc6b82b7bea637c6 100644
--- a/skeleton_utils.py
+++ b/skeleton_utils.py
@@ -1,64 +1,75 @@
 # -*- coding: utf-8 -*-
 """Helpers for normalizing skeleton payloads returned by LLM."""
 
 from __future__ import annotations
 
 import logging
 from typing import Any, Dict
 
 
 LOGGER = logging.getLogger(__name__)
 
 _CANONICAL_CONCLUSION_KEYS = ("conclusion", "outro", "ending", "final", "summary")
+_DEFAULT_MAIN_PLACEHOLDER = (
+    "Этот раздел будет расширен детальными рекомендациями в финальной версии статьи."
+)
 
 
 def _as_list(value: Any) -> list:
     if isinstance(value, list):
         return list(value)
     if value is None:
         return []
     return [value]
 
 
 def _describe_keys(payload: Dict[str, Any]) -> str:
     descriptors = []
     if "intro" in payload:
         descriptors.append("intro")
     if "main" in payload:
         descriptors.append("main[]")
     if "faq" in payload:
         descriptors.append("faq[]")
     if "conclusion" in payload:
         descriptors.append("conclusion")
     return ",".join(descriptors)
 
 
 def normalize_skeleton_payload(payload: Any) -> Any:
     """Return a normalized skeleton payload with canonical keys."""
 
     if not isinstance(payload, dict):
         return payload
 
     normalized: Dict[str, Any] = dict(payload)
 
     conclusion_value = None
     for key in _CANONICAL_CONCLUSION_KEYS:
         if key in normalized:
             value = normalized.get(key)
             if value is not None and str(value).strip():
                 conclusion_value = value
                 break
     if conclusion_value is not None:
         normalized["conclusion"] = conclusion_value
     for legacy_key in ("outro", "ending", "final", "summary"):
         normalized.pop(legacy_key, None)
 
-    normalized["main"] = _as_list(normalized.get("main"))
+    normalized_main = [
+        str(item or "").strip() for item in _as_list(normalized.get("main")) if str(item or "").strip()
+    ]
+    if len(normalized_main) > 6:
+        LOGGER.info("LOG:SKELETON_MAIN_TRIM normalize from=%d to=6", len(normalized_main))
+        normalized_main = normalized_main[:6]
+    while len(normalized_main) < 3:
+        normalized_main.append(_DEFAULT_MAIN_PLACEHOLDER)
+    normalized["main"] = normalized_main
     normalized["faq"] = _as_list(normalized.get("faq"))
 
     keys_descriptor = _describe_keys(normalized)
     LOGGER.info("LOG:SKELETON_NORMALIZED keys=%s", keys_descriptor)
     return normalized
 
 
 __all__ = ["normalize_skeleton_payload"]
diff --git a/tests/test_length_controller.py b/tests/test_length_controller.py
new file mode 100644
index 0000000000000000000000000000000000000000..ed8655c1eecb3923f35efe111f7090a0118c8211
--- /dev/null
+++ b/tests/test_length_controller.py
@@ -0,0 +1,41 @@
+from length_controller import ensure_article_length
+from validators import length_no_spaces
+
+
+def _base_article() -> str:
+    faq_pairs = []
+    for idx in range(1, 6):
+        faq_pairs.append(f"**Вопрос {idx}.** Что-то?")
+        faq_pairs.append(f"**Ответ.** Ответ {idx}.")
+        faq_pairs.append("")
+    faq_section = "\n".join(["## FAQ", "<!--FAQ_START-->"] + faq_pairs[:-1] + ["<!--FAQ_END-->"])
+    return (
+        "# Заголовок\n\n"
+        "## Раздел 1\n\n"
+        "Короткий абзац с базовой мыслью.\n\n"
+        "## Раздел 2\n\n"
+        "Ещё один короткий абзац.\n\n"
+        f"{faq_section}\n\n"
+        "## Заключение\n\n"
+        "Финальный вывод.\n"
+    )
+
+
+def test_ensure_article_length_extends_short_article():
+    article = _base_article()
+    result = ensure_article_length(article, min_chars=800, max_chars=1200, protected_blocks=[])
+
+    assert result.success is True
+    assert result.adjusted is True
+    assert result.length >= 800
+    assert length_no_spaces(result.text) == result.length
+
+
+def test_ensure_article_length_trims_long_article():
+    extra = "\n\n".join(f"Дополнительный абзац {idx}." for idx in range(12))
+    article = _base_article().replace("## FAQ", f"{extra}\n\n## FAQ")
+    result = ensure_article_length(article, min_chars=500, max_chars=600, protected_blocks=[])
+
+    assert result.success is True
+    assert result.length <= 600
+    assert length_no_spaces(result.text) == result.length
diff --git a/tests/test_skeleton_utils.py b/tests/test_skeleton_utils.py
index a1af4452e9c6b0430c5de73779968be4de770ca2..8f3705555779eaec3a14853a47697bb118baa54e 100644
--- a/tests/test_skeleton_utils.py
+++ b/tests/test_skeleton_utils.py
@@ -1,17 +1,32 @@
 from skeleton_utils import normalize_skeleton_payload
 
 
 def test_normalize_skeleton_payload_standardizes_keys():
     raw_payload = {
         "intro": "Intro",
         "main": "Section",
         "faq": {"q": "Q?", "a": "A!"},
         "outro": "Bye",
     }
 
     normalized = normalize_skeleton_payload(raw_payload)
 
     assert "outro" not in normalized
     assert normalized["conclusion"] == "Bye"
-    assert normalized["main"] == ["Section"]
+    assert len(normalized["main"]) == 3
+    assert normalized["main"][0] == "Section"
     assert normalized["faq"] == [{"q": "Q?", "a": "A!"}]
+
+
+def test_normalize_skeleton_payload_enforces_main_range():
+    raw_payload = {
+        "intro": "Intro",
+        "main": [f"Block {idx}" for idx in range(10)],
+        "faq": [],
+        "conclusion": "Bye",
+    }
+
+    normalized = normalize_skeleton_payload(raw_payload)
+
+    assert len(normalized["main"]) == 6
+    assert normalized["main"][0] == "Block 0"

